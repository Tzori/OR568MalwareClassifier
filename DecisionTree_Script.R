# Relevant Libraries
library(AppliedPredictiveModeling)
library(caret)
library(e1071)
library(corrplot)
library(lattice)
library(dplyr)

library(rpart)
library(rpart.plot)
library(pROC)
library(ROCR)

# Load dataset
# Set your working directory to the directory to where all project R Scripts 
cwd <- getwd()
file.name <- "Kaggle-data-FINAL.csv"
paste(cwd, file.name ,sep="/")
df <- read.csv(paste(cwd, file.name ,sep="/"))

df = read.csv('/Users/18043/Downloads/Kaggle-data-FINAL.csv')

# Label the response variable column name
response_var <- "legitimate" 
## Confirm there are no nulls
sum(is.na(df))
## Check for near zero variance using the nearZeroVar function
zeroVar <- nearZeroVar(df, saveMetrics=FALSE)
## Column index 10, 30, 31, 32, 33, and 47 all have zero  variance
colnames(df[c(10,30,31,32,33,47)])
##Dropping near zero variance columns
df_trans1 <- df[, -c(10,30,31,32,33,47)] 
##Check to see what class each attribute is
sapply(df_trans1, class)
##Can see that md5 is a character class so we will drop this as it is not needed
df_trans2 <- df_trans1[,-2]
colnames(df_trans2)

## Find highly correlated variables; remove corr magnitude .8 or higher
corr_matrix <- cor(df_trans2)
high_corr <- findCorrelation(corr_matrix, cutoff = 0.8)
removed_variables <- names(df_trans2)[high_corr]
removed_variables

df_trans3 <- df_trans2[, -high_corr]
dim(df_trans3)
head(df_trans3)
## Next step will be to standardrize the variables
## https://www.r-bloggers.com/2022/07/how-to-standardize-data-in-r/
df_stdz <- df_trans3 %>%
  mutate_at(-which(names(df_trans3) == response_var), ~(scale(.) %>% 
                                                          as.vector))
# Matts normalization
df_stdz <- df_trans3 %>%
  mutate_at(-which(names(df_trans3) == response_var), ~( (.-min(.))/(max(.)-min(.)) ))

# df_stdz <- mutate_all(df_stdz, function(x) as.numeric(as.character(x)))

## Now that all variables have been standardized, a test train split will be created
## I will be using a 70/30 split
set.seed(568)
# Create the partition index with a 70/30 split
index <- createDataPartition(y = df_stdz$legitimate, p = 0.7, list = FALSE)

# Create the train and test sets
train <- df_stdz[index, ]
test <- df_stdz[-index, ]
## Create the df with X and Y variables
# Remove "legitimate" column from training and test datasets
x_train <- train[, -which(names(train) == response_var)]
y_train <- train[, which(names(train) == response_var)]
y_train <- factor(y_train)
x_test <- test[, -which(names(test) == response_var)]
y_test <- test[, which(names(test) == response_var)]

## Set up the control option
# control <- rfeControl(functions = lrFuncs,
#                       method = "repeatedcv", ## Repeated CV
#                       repeats = 5, ## Number of repeats
#                       number = 10, ## Number of folds
#                       verbose = FALSE
## Set up the control option

control <- rfeControl(functions = lrFuncs,
                      method = "repeatedcv", ## Repeated CV
                      repeats = 2,
                      number = 3, ## Number of folds
                      verbose = FALSE
)



################################
#################################
#first tree attempt

first_tree <- rpart( y_train ~ ., data=x_train, method="anova", control=rpart.control(cp=0.01,maxdepth=6) )
#tree plotting
prp(first_tree, space=4, split.cex = 1.5, nn.border.col=0)

#also tree plotting
first_tree_plot = as.party(first_tree)
plot(first_tree_plot)

# predict legitmate with this classification tree: 
first_tree_test = predict()
first_tree_test = predict(first_tree,newdata=x_test)

## performance evaluation
first_tree_test_results = postResample(pred=first_tree_test, obs=y_test)
first_tree_test_results

rpart.plot(first_tree)
printcp(first_tree)
plotcp(first_tree)




################################
#################################
#second tree attempt
second_tree <- rpart( y_train ~ .- ID, data=x_train, method="anova", control=rpart.control(cp=0.01,maxdepth=6) )
#tree plotting
prp(second_tree, space=4, split.cex = 1.5, nn.border.col=0)

second_tree_plot = as.party(second_tree)
plot(second_tree_plot)


################################
#################################
#third tree attempt
third_tree <- rpart( y_train ~ .- ID, data=x_train, method="class", control=rpart.control(cp=0.01,maxdepth=6, minbucket=5) )
#tree plotting
prp(third_tree, space=4, split.cex = 1.5, nn.border.col=0)

third_tree_plot = as.party(third_tree)
plot(third_tree_plot)



# predict legitmate with this classification tree: 
third_tree_test = predict(third_tree,newdata=x_test, type='class')

## performance evaluation
third_tree_test_results = postResample(pred=third_tree_test, obs=y_test)
third_tree_test_results

rpart.plot(third_tree)
printcp(third_tree)
plotcp(third_tree)

#confusion matrix
#TRAIN DATA
third_tree_train = predict(third_tree,newdata=x_train, type='class')
confusionMatrix(third_tree_train, y_train)
#TEST DATA
third_tree_test = predict(third_tree,newdata=x_test, type='class')
confusionMatrix(third_tree_test, as.factor(y_test))

#ROC
#value of 2 here predicts legit=1, change it to a 1 and it predicts legit=0
tree.preds <- predict(third_tree, x_test, type="prob")[, 2]
tree.roc <- roc(y_test, tree.preds)
print(tree.roc)
plot(tree.roc)


## performance evaluation
third_tree_test_results = postResample(pred=third_tree_test, obs=as.factor(y_test))
third_tree_test_results

rpart.plot(third_tree)
printcp(thirdt_tree)
plotcp(third_tree)





##########
#Model tuning
install.packages("Metrics")
install.packages("plotly")
library(dplyr)
library(rpart)
library(rpart.plot)
library(Metrics)
library(mlr)
library(ggplot2)
library(plotly)

getParamSet("classif.rpart")

d.tree.params <- makeClassifTask(
  data=train, 
  target="legitimate"
)

param_grid <- makeParamSet( 
  makeDiscreteParam("maxdepth", values=1:30))

# Define Grid
control_grid = makeTuneControlGrid()
# Define Cross Validation
resample = makeResampleDesc("CV", iters = 3L)
# Define Measure
measure = acc

#https://towardsdatascience.com/decision-tree-hyperparameter-tuning-in-r-using-mlr-3248bfd2d88c
set.seed(568)
dt_tuneparam <- tuneParams(learner='classif.rpart', 
                           task=d.tree.params, 
                           resampling = resample,
                           measures = measure,
                           par.set=param_grid, 
                           control=control_grid, 
                           show.info = TRUE)

result_hyperparam <- generateHyperParsEffectData(dt_tuneparam, partial.dep = TRUE)

ggplot(
  data = result_hyperparam$data,
  aes(x = maxdepth, y=acc.test.mean)
) + geom_line(color = 'darkblue')

dt_tuneparam
dt_tuneparam$x


best_parameters = setHyperPars(
  makeLearner("classif.rpart"), 
  par.vals = dt_tuneparam$x
)



param_grid_multi <- makeParamSet( 
  makeDiscreteParam("maxdepth", values=1:30),
  makeNumericParam("cp", lower = 0.001, upper = 0.01),
  makeDiscreteParam("minsplit", values=1:30)
)
#runs for hours
dt_tuneparam_multi <- tuneParams(learner='classif.rpart', 
                                 task=d.tree.params, 
                                 resampling = resample,
                                 measures = measure,
                                 par.set=param_grid_multi, 
                                 control=control_grid, 
                                 show.info = TRUE)
#[Tune] Result: maxdepth=17; cp=0.001; minsplit=19 : acc.test.mean=0.9689460





#################################
#Final tree after tuning
final_tree <- rpart( y_train ~ .- ID, data=x_train, method="class", control=rpart.control(cp=0.001,maxdepth=17, minsplit = 19) )
#tree plotting
prp(final_tree, space=4, split.cex = 1.5, nn.border.col=0)

final_tree_plot = as.party(final_tree)
plot(final_tree_plot)

# predict legitmate with this classification tree: 
final_tree_train = predict(final_tree,newdata=x_train, type='class')

## performance evaluation
final_tree_train_results = postResample(pred=final_tree_train, obs=y_train)
final_tree_train_results

# predict legitmate with this classification tree: 
final_tree_test = predict(final_tree,newdata=x_test, type='class')

## performance evaluation
final_tree_test_results = postResample(pred=final_tree_test, obs=y_test)
final_tree_test_results

rpart.plot(final_tree)
printcp(final_tree)
plotcp(final_tree)

#confusion matrix
#TRAIN DATA
final_tree_train = predict(final_tree,newdata=x_train, type='class')
confusionMatrix(final_tree_train, y_train)
#TEST DATA
final_tree_test = predict(final_tree,newdata=x_test, type='class')
confusionMatrix(final_tree_test, as.factor(y_test))

#ROC
#value of 2 here predicts legit=1, change it to a 1 and it predicts legit=0
tree.preds.final <- predict(final_tree, x_test, type="prob")[, 2]
tree.roc.final <- roc(y_test, tree.preds.final)
print(tree.roc.final)
plot(tree.roc.final)


## performance evaluation
final_tree_test_results = postResample(pred=final_tree_test, obs=as.factor(y_test))
final_tree_test_results

rpart.plot(final_tree)
printcp(final_tree)
plotcp(final_tree)


