## Import the package and libraries that will be used for this modeling

library(AppliedPredictiveModeling)
library(caret)
library(e1071)
library(corrplot)
library(lattice)
library(dplyr)
library(caretEnsemble)
library(ROCR)
# Load dataset for your machine 
# Set your working directory to the directory to where all project R Scripts 
cwd <- getwd()
file.name <- "Kaggle-data-FINAL.csv"
paste(cwd, file.name ,sep="/")
df <- read.csv(paste(cwd, file.name ,sep="/"))
# Label the response variable column name
response_var <- "legitimate" 
## Confirm there are no nulls
sum(is.na(df))
## Check for near zero variance using the nearZeroVar function
zeroVar <- nearZeroVar(df, saveMetrics=FALSE)
## Column index 10, 30, 31, 32, 33, and 47 all have zero  variance
colnames(df[c(10,30,31,32,33,47)])
##Dropping near zero variance columns
df_trans1 <- df[, -c(10,30,31,32,33,47)] 
##Drop the ID column because this is an index and is non-informational as well as the md5 column
df_trans1 <- df_trans1[, -c(1,2)]
head(df_trans1)
## Find highly correlated variables; remove corr magnitude .8 or higher
corr_matrix <- cor(df_trans1)
high_corr <- findCorrelation(corr_matrix, cutoff = 0.8)
removed_variables <- names(df_trans1)[high_corr]
removed_variables

##Remove highly correlated variables from data frame
df_trans2 <- df_trans1[, -high_corr]
##Convert outcome variable to 2-level factor
df_trans2$legitimate <- as.factor(df_trans2$legitimate)

##Next the data partition will be created
set.seed(568)
index <- createDataPartition(y=df_trans2$legitimate, p = 0.7, list = FALSE)
train <- df_trans2[index, ]
test <- df_trans2[-index, ]
x_train <- train[, -which(names(train) == response_var)]
y_train <- train[, which(names(train) == response_var)]
x_test <- test[, -which(names(test) == response_var)]
y_test <- test[, which(names(test) == response_var)]
##Bagged Decision Tree
set.seed(568)
ctrl <- trainControl(method = "repeatedcv", number = 2, repeats = 2)
bag_model <- train(legitimate~., data = train, method = "treebag", metric = "Accuracy", trControl = ctrl)
bag_model

## Check the confusion Matrix on the test set
bag_modelCM <- confusionMatrix(data = predict(bag_model, x_test), reference = y_test)
bag_modelCM
#######################################################################################################
#######################################################################################################
                                  #######THIS IS WHERE I AM STRUGGLING TO GET THE ROC CURVE############ 
## Create new data frame with predicted & Observed values to create ROC curve
bag_results <- data.frame(obs = y_test)
bag_results$prob <- predict(bag_model, x_test, type = "prob")
bag_results$pred <- predict(bag_model, x_test)
## Create the ROC curve
bag_roc <- roc(response = bag_model$pred$obs, predictor = bag_model$pred,
               levels = rev(levels(bag_model$pred$obs)))

bagged_kappa <- bag_modelCM$overall['Kappa']
bagged_kappa
##Plot the Roc Curve
bag_roc <- roc(y_test, bag_pred, plot=TRUE)
##Take a look at variable importance
var_importance <- varImp(bag_model)
plot(var_importance, ylab = "Variable", main = "Variable Impotance for Bagged Decision Tree")


##Next a random forest model will be created
set.seed(568)
rand_forest <- train(legitimate~., data = train, method = "rf", metric = "Accuracy",
                     trControl = ctrl)
rand_forest
## Check the confusion Matrix on the test set
rand_forestCM <- confusionMatrix(data = predict(rand_forest, x_test), reference = y_test)
rand_forestCM
## Create plot of variable importance
var_importance2 <-varImp(rand_forest)
plot(var_importance2, ylab = "Variable", main = "Variable Impotance for Random Forest")

############################ Stochastic Gradient Boosting #########################
set.seed(568)
grad_boost_model <- train(legitimate~., data = train, method = "gbm", metric = "Accuracy",
                          trControl = ctrl)
grad_boost_model
## Check the confusion Matrix on the test set
grad_boost_modelCM <- confusionMatrix(data = predict(grad_boost_model, x_test), reference = y_test)
grad_boost_modelCM


######################## Stacking Model ############################
## Need to rename class outcome  because its failing on the stacking model
train2 %>%
  mutate(legitimate = factor(legitimate,
                             labels = make.names(levels(legitimate))))
test2 %>%
  mutate(legitimate = factor(legitimate,
                             labels = make.names(levels(legitimate))))
head(test2)
set.seed(568)
ctrl2 <- trainControl(method = "repeatedcv", number = 2, repeats = 2, 
                      savePredictions = TRUE, classProbs = TRUE)
## Saw this on a source -- list out algorithms that will be used
algo_to_use <- c('rpart', 'glm', 'knn', 'svmRadial')
stacked_model <- caretList(legitimate~., data = train %>%
                             mutate(legitimate = factor(legitimate,
                                                        labels = make.names(levels(legitimate)))), trControl = ctrl2,
                           methodList = algo_to_use)
stack_results <- resamples(stacked_model)
summary(stack_results)

## Use the outcomes from the various models to create a logitsic regression
set.seed(568)
glm_stack_model <- caretStack(stacked_model, method = "glm", metric = "Accuracy",
                              trControl = ctrl2)
glm_stack_model

##Apply model to test set
glm_stack_modelCM <- confusionMatrix(data = predict(glm_stack_model, x_test), reference = y_test %>%
                                       mutate(legitimate = factor(legitimate,
                                                                  labels = make.names(levels(legitimate)))))
glm_stack_modelCM

