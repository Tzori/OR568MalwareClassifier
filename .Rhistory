library(lattice)
library(AppliedPredictiveModeling)
library(dplyr)
library(tidyr)
library(ggplot2)
library(corrplot)
library(caret)
library(e1071)
cwd <- getwd()
file.name <- "Kaggle-data-FINAL.csv"
paste(cwd, file.name ,sep="/")
kdatafinal <- read.csv(paste(cwd, file.name ,sep="/"))
get()
setwd("C:/Rprojects/MalwareDataset - Github/OR568MalwareClassifier/OR568MalwareClassifier")
getwd()
library(lattice)
library(AppliedPredictiveModeling)
library(dplyr)
library(tidyr)
library(ggplot2)
library(corrplot)
library(caret)
library(e1071)
cwd <- getwd()
file.name <- "Kaggle-data-FINAL.csv"
paste(cwd, file.name ,sep="/")
kdatafinal <- read.csv(paste(cwd, file.name ,sep="/"))
kdatafinal
str(kdatafinal)
str(newMalwaredf)# It has 42 with X col. legitimate col is int.
skewValues <- apply(pcadata1,2,skewness)
# PCA analysis
#Running skeweness to all the dataset (malwaredf)
pcadata1 <- pcadata[,-41]
pcadata <- newMalwaredf[,-1]
str(newMalwaredf)# It has 42 with X col. legitimate col is int.
str(kdatafinal)
str(kdatafinal)
str(newMalwaredf)
library(lattice)
library(AppliedPredictiveModeling)
library(dplyr)
library(tidyr)
library(ggplot2)
library(corrplot)
library(caret)
library(e1071)
cwd <- getwd()
file.name <- "Kaggle-data-FINAL.csv"
paste(cwd, file.name ,sep="/")
kdatafinal <- read.csv(paste(cwd, file.name ,sep="/"))
kdatafinal
str(kdatafinal)# I am removing md5
str(newMalwaredf)# It has 42 with X col. legitimate col is int.
# Find out the length of the data frame
## Check for near zero variance using the nearZeroVar function
zeroVar <- nearZeroVar(df, saveMetrics=FALSE)
## Column index 10, 30, 31, 32, 33, and 47 all have zero  variance
colnames(df[c(10,30,31,32,33,47)])
##Dropping near zero variance columns
df_trans1 <- df[, -c(10,30,31,32,33,47)]
##Drop the ID column because this is an index and is non-informational as well as the md5 column
df_trans1 <- df_trans1[, -c(1,2)]
# Find out the length of the data frame
## Check for near zero variance using the nearZeroVar function
zeroVar <- nearZeroVar(df, saveMetrics=FALSE)
pcadata <- kdatafinal[,-1]
str(pcadata)
length(pcadata)
#Running the PCA for the entire final data set
pcaM <- prcomp(pcadata1, center=TRUE, scale. = TRUE )
#Running correlation for the predictors
corrMalwaredf <- cor(pcadata)
length(highCorr)
head(highCorr)
filteredMalwaredf <- pcadata[, -highCorr]#Filtering the highcorr variables, the data set gets
filteredMalwaredf
filteredMalwaredf <- pcadata[, -highCorr]#Filtering the highcorr variables, the data set gets
filteredMalwaredf
cwd <- getwd()
file.name <- "ImportVar10.csv"
paste(cwd, file.name ,sep="/")
ImportVar10 <- read.csv(paste(cwd, file.name ,sep="/"))
# Label the response variable column name
response_var <- "legitimate"
#Step 1 - load the necessary packages
install.packages("randomForest")
#===============================================================================
# Split Test Train Data
#===============================================================================
set.seed(568)
#Running the PCA for the entire final data set
pcaM <- prcomp(pcadata1, center=TRUE, scale. = TRUE )
View(pcadata)
#===============================================================================
# Pre-Process Data
#===============================================================================
null_cols <- which(colSums(is.na(ImportVar10)) > 0)
null_cols
sum(is.na(ImportVar10))
zeroVar <- nearZeroVar(ImportVar10, saveMetrics=FALSE)
zeroVar
corr_matrix <- cor(ImportVar10)
high_corr <- findCorrelation(corr_matrix, cutoff = 0.8)
high_corr
skewValues <- apply(ImportVar10, 2, skewness)
head(skewValues)
cor(ImportVar10)
# Label the response variable column name
response_var <- "legitimate"
#Step 1 - load the necessary packages
#install.packages("randomForest")
library(randomForest)
#-----------------Tuning------------------------
str(malwaredf)
#fit the random forest model
malwareModel <- randomForest(formula = legitimate ~ ., data = traindata)
#display fitted model
malwareModel
#find number of trees that produce lowest test MSE
which.min (malwreModel$mse)
#fit the random forest model
malwareModel <- randomForest(formula = legitimate ~ ., data = traindata)
library(caret)
trainingindex <- createDataPartition(y=ImportVar10$legitimate, p = .70,list= FALSE)
head(trainingindex)
traindata <-ImportVar10[trainingindex, ]
testdata <- ImportVar10[-trainingindex, ]
x_train <- traindata[, -which(names(traindata) == response_var)]
y_train <- traindata[, which(names(traindata) == response_var)]
x_test <- testdata[, -which(names(testdata) == response_var)]
y_test <- testdata[, which(names(testdata) == response_var)]
#===============================================================================
# Creating the control, and grid parameters
#===============================================================================
library(mlr)
control <- trainControl(method = "cv", number=10, classProbs = TRUE)
control
grid = expand.grid(.mtry = 4)
grid
resample = makeResampleDesc("CV", iters = 3L)
#-----------------------------------------------------------------
#Random forest using traindata.
library(randomForest)
library(rpart)
library(rpart.plot)
library(ROCR)
library(caretEnsemble)
library(caretEnsemble)
rfModel = randomForest( legitimate~.,
data= traindata,
mtry= 4, ntree=501,
importance = TRUE)
rfModel
plot(rfModel, main = "Random Forest Model graph", legend('topright', legend=c('Malicious', 'OOB', 'Not malicious'), col=c('red', 'Black', 'Green'), lty = 1))
tail(plot(rfModel))
plot(rfModel, main = "Random Forest Model graph", legend('topright', legend=c('Malicious', 'OOB', 'Not malicious'), col=c('red', 'Black', 'Green'), lty = 1))
# predict
rf_predict = predict(rfModel,newdata= data.frame(x_test)) # it run
rf_predict
## performance evaluation
rfPR = postResample(pred=rf_predict, obs= y_test) # it run
rfPR
#------------# Calculate the ROC curve and AUC for RF model--------------------------
# Convert binary factor to numeric vector
y_test_numeric <- as.numeric(as.character(y_test))
rf_predict_numeric <- as.numeric(as.character(rf_predict))
roc_dataRF <- roc(y_test_numeric, rf_predict_numeric)
#------------# Calculate the ROC curve and AUC for RF model--------------------------
# Convert binary factor to numeric vector
library(pROC)
y_test_numeric <- as.numeric(as.character(y_test))
rf_predict_numeric <- as.numeric(as.character(rf_predict))
roc_dataRF <- roc(y_test_numeric, rf_predict_numeric)
auc <- auc(roc_dataRF)
auc # shows the value of AUC. It is 0.9936
#-------------confusion_matrix for RF model---------------------------------------
#str(rf_predict)
#str(y_test)
confusionMatrixRF <- confusionMatrix(rf_predict, y_test)
print(confusionMatrixRF)
print(confusionMatrixRF$table) # it shows a count of predictions per option of
#-------------confusion_matrix for RF model---------------------------------------
#str(rf_predict)
#str(y_test)
confusionMatrixRF <- confusionMatrix(rf_predict, y_test)
ggroc(roc_dataRF, legacy.axes = TRUE, color = "purple") +
geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
labs(title = paste("Random Forest B ROC
(AUC =", round(auc, 2), ")"),
#subtitle = svm.subtitle,
x = "Specificity",
y = "Sensitivity",
color = "SVM") +
theme_bw()
library(caret)
#-------------confusion_matrix for RF model---------------------------------------
library(caret)
confusionMatrixRF <- confusionMatrix(rf_predict, y_test)
print(confusionMatrixRF)
print(confusionMatrixRF$table) # it shows a count of predictions per option of
#-------------confusion_matrix for RF model---------------------------------------
library(caret)
confusionMatrixRF <- confusionMatrix(rf_predict, y_test)
# Creating a plot between Characteristics and legitimate.
ggplot(traindata, aes( Characteristics, legitimate )) +
geom_point(colour = "red") +
#geom_errorbarh(height=.2) +
labs(title='Title Of Plot', x='Predictor', y = ' Outcome')
set.seed(568)
#fit the random forest model
malwareModel <- randomForest(formula = legitimate ~ ., data = traindata)
# Creating a plot between Characteristics and legitimate.
ggplot(traindata, aes( Characteristics, legitimate )) +
geom_point(colour = "red") +
#geom_errorbarh(height=.2) +
labs(title='Title Of Plot', x='Predictor', y = ' Outcome')
set.seed(568)
#fit the random forest model
malwareModel <- randomForest(formula = legitimate ~ ., data = traindata)
#display fitted model
malwareModel
View(pcadata)
#display fitted model
malwareModel
#find number of trees that produce lowest test MSE
which.min (malwreModel$mse)
#find RMSE of best model
sqrt(malwareModel$mse[which.min(model$mse)])
#plot the model
Plot(malwareModel)
#find number of treaes that produce lowest test MSE
which.min (malwareModel$mse)
#find RMSE of best model
sqrt(malwareModel$mse[which.min(model$mse)])
#plot the model
Plot(malwareModel)
#find RMSE of best model
sqrt(malwareModel$mse[which.min(model$mse)])
#find RMSE of best model
sqrt(malwareModel$mse[which.min(malwareModel$mse)])
#plot the model
Plot(malwareModel)
#produce variable importance plot
varImpPlot(malwareModel)
#Step 3: Tune the Model
model_tuned <- tuneRF(
x= ImportVar10[,-11], #define predictor variables
y= ImportVar10$legitimate, #define response variable
ntreeTry=500,
mtryStart=4,
stepFactor=1.5,
improve=0.01,
trace=FALSE #don't show real-time progress
)
