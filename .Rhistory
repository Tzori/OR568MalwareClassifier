geom_col(position = position_dodge(width = 0.5)) +
labs(title = "Proportion of Missing Attributes",
x = "Proportion") +
scale_fill_manual(values=c("forestgreen","red")) +
theme(axis.text.y = element_text(size = 8))
# Which attributes are missing?
attributes.na <- colSums(is.na(kaggle.data))
attributes.na
class_table <- table(kaggle.data$Machine[kaggle.data$Machine %in% incomplete.machines$Machine])
class_table[class_table > 0]
sum(class_table)
total.na <- sum(is.na(kaggle.data))
print(paste("The total number of na values is: ", total.na))
attributes.na <- colSums(is.na(kaggle.data))
attributes.na
percentage.na <- round(100 * attributes.na / total.na, 1)
paste(names(percentage.na), ": ", percentage.na, "%", sep="")
unique(kaggle.data$X)
View(filter(kaggle.data, X == 0)
)
library(ggplot2)
ggplot(kaggle.data, aes(x=SizeOfCode)) +
geom_histogram(binwidth=100000, fill="cornflowerblue", color="white")
#labs(title="Size of Code Distribution", x="Size of Code", y="Count")
# corrplot
num_vars <- kaggle.data[sapply(kaggle.data, is.numeric)]
corr_matrix <- cor(num_vars)
corrplot(corr_matrix)
# ==============================================================================
# ggcorrplot test
library(ggplot2)
library(ggcorrplot)
# Subset numeric variables from kaggle.data
num_vars <- kaggle.data[sapply(kaggle.data, is.numeric)]
# Calculate correlation matrix and replace missing/invalid values with zeros
corr_matrix <- cor(num_vars, use = "pairwise.complete.obs")
corr_matrix[is.na(corr_matrix) | is.infinite(corr_matrix)] <- 0
# Create ggcorrplot with larger space between attribute labels
ggcorrplot(corr_matrix, hc.order = TRUE,
ggtext = ggplot2::element_text(size = 8, hjust = 0.5, margin = margin(t = 0, b = 5)))
ggcorrplot(corr_matrix, hc.order = TRUE)
# ==============================================================================
# ==============================================================================
library(ggplot2)
# Subset numeric variables from kaggle.data
num_vars <- kaggle.data[sapply(kaggle.data, is.numeric)]
# Calculate correlation matrix and replace missing/invalid values with zeros
corr_matrix <- cor(num_vars, use = "pairwise.complete.obs")
corr_matrix[is.na(corr_matrix) | is.infinite(corr_matrix)] <- 0
# Convert correlation matrix to dataframe
df <- reshape2::melt(corr_matrix)
# Create heatmap with coral shade for negative correlations and black box borders
ggplot(df, aes(Var1, Var2, fill = value)) +
geom_tile(color = "black") +
scale_fill_gradient2(low = "coral", mid = "white", high = "steelblue",
midpoint = 0, limits = c(-1,1), guide = "colorbar") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(title = "Malware Data Variable Correlation Heatmap", x = "Variable 1", y = "Variable 2") +
geom_rect(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, fill = NA, color = "black")
# ==============================================================================
# Metadata Plots
# Load dataset
# Get number of columns for each data type
num_numeric <- sum(sapply(kaggle.data, is.numeric))
num_factor <- sum(sapply(kaggle.data, is.factor))
num_character <- sum(sapply(kaggle.data, is.character))
num_logical <- sum(sapply(kaggle.data, is.logical))
# Create bar plot
barplot(
c(num_numeric, num_factor, num_character, num_logical),
names.arg = c("Numeric", "Factor", "Character", "Logical"),
xlab = "Data Types",
ylab = "Number of Columns",
main = "Data Types in kaggle.data"
)
library(ggplot2)
# Get number of columns for each data type
num_numeric <- sum(sapply(kaggle.data, is.numeric))
num_factor <- sum(sapply(kaggle.data, is.factor))
num_character <- sum(sapply(kaggle.data, is.character))
num_logical <- sum(sapply(kaggle.data, is.logical))
# Create data frame for bar plot
data <- data.frame(
Data_Types = c("Numeric", "Factor", "Character", "Logical"),
Number_of_Columns = c(num_numeric, num_factor, num_character, num_logical)
)
# Sort the data frame by Number_of_Columns in descending order
data <- data[order(-data$Number_of_Columns), ]
# Create the ggplot bar plot
ggplot(data, aes(x = reorder(Data_Types, Number_of_Columns), y = Number_of_Columns, fill = Data_Types)) +
geom_bar(stat = "identity", color="black") +
geom_text(aes(label = Number_of_Columns), hjust = -0.5, vjust=-0.5, color = "black") +
coord_flip() +
labs(x = "Data Types", y = "Number of Attributes",
title = "Data Types in Malware Classifier Data") +
theme(legend.position = "bottom")
# Basic violin plot
library(ggplot2)
p <- ggplot(kaggle.data, aes(x=SizeOfCode, y=SectionsMeanEntropy)) +
geom_violin()
p
# Rotate the violin plot
p + coord_flip()
# Set trim argument to FALSE
ggplot(kaggle.data, aes(x=x.var, y=y.var)) +
geom_violin(trim=FALSE)
setwd("C:/Dev/OR568MalwareClassifier")
library(dplyr)
library(ggplot2)
library(caret)
library(corrplot)
library(lattice)
library(e1071)
library(ggpubr)
library(pROC)
#===============================================================================
# Load dataset for your machine
#===============================================================================
# Set your working directory to the directory where all project R Scripts
cwd <- getwd()
file.name <- "Kaggle-data-FINAL.csv"
paste(cwd, file.name ,sep="/")
df <- read.csv(paste(cwd, file.name ,sep="/"))
data.load <- df
#===============================================================================
# Pre-Process Data
# Label the response variable column name
response_var <- "legitimate"
## Confirm there are no nulls
sum(is.na(df))
## Check for near zero variance using the nearZeroVar function
zeroVar <- nearZeroVar(df, saveMetrics=FALSE)
## Column index 10, 30, 31, 32, 33, and 47 all have zero  variance
zeroVar.names <- colnames(df[zeroVar])
trans1 <- (paste("ZeroVar column removed:", zeroVar.names, collapse = "\n"))
##Dropping near zero variance columns
df_trans1 <- df[, -zeroVar]
##Drop the ID column because this is an index and is non-informational as well as the md5 column
id.columns <- colnames(df_trans1[1:2])
df_trans2 <- select(df_trans1, -id.columns)
trans2 <- (paste("ID column removed:", id.columns, collapse = "\n"))
## Find highly correlated variables; remove corr magnitude .8 or higher
corr_matrix <- cor(df_trans2)
high_corr <- findCorrelation(corr_matrix, cutoff = 0.8)
high.corr.names <- names(df_trans2)[high_corr]
trans3 <- (paste("High Correlation removed:", high.corr.names, collapse = "\n"))
##Remove highly correlated variables from data frame
df_trans3 <- df_trans2[, -high_corr]
##Convert outcome variable to 2-level factor
df_trans3$legitimate <- as.factor(df_trans3$legitimate)
# Removal Recap
df.preprocessed <- df_trans3
cat(trans1, trans2, trans3, sep="\n")
#===============================================================================
# Split Test Train Data
set.seed(568)
index <- createDataPartition(y=df.preprocessed$legitimate, p = 0.1, list = FALSE)
train <- df.preprocessed[index, ]
test <- df.preprocessed[-index, ]
x_train <- train[, -which(names(train) == response_var)]
y_train <- train[, which(names(train) == response_var)]
x_test <- test[, -which(names(test) == response_var)]
y_test <- test[, which(names(test) == response_var)]
#-------------------------------------------------------------------------------
library(caret)
# Define the training control
ctrl <- trainControl(method = "cv", number = 10)
{ # Polynomial Model Timed
poly.start <- Sys.time()
svm_poly <- train(legitimate ~ ., data = train, method = "svmPoly", trControl = ctrl, degree = 2, coef0 = 1)
poly.end <- Sys.time()
poly.time <- poly.end - poly.start
poly.time
}
install.packages("citeproc")
library(citeproc)
# Read the library names from R libraries.txt
library_names <- readLines("R libraries.txt")
library_names
# Loop through each library name and get the bibliographic information
bib_entries <- list()
for (lib_name in library_names) {
bib_entries[[lib_name]] <- csljson_to_bibtex(csl_json_search(lib_name))
}
# Load the required libraries
library(tools)
library(citations)
install.packages("citations")
library(citations)
# Define the name of the file containing the list of R packages
lib_file <- "R_libraries.txt"
# Read in the list of R packages
libs <- readLines(lib_file)
setwd("C:/Dev/OR568MalwareClassifier")
# Define the name of the file containing the list of R packages
lib_file <- "R libraries.txt"
# Read in the list of R packages
libs <- readLines(lib_file)
# Generate bibtex citations for each R package
cits <- generate_citation("pkg", libs)
generate_citation
library(citations)
# Load the required libraries
library(tools)
library(RefManageR)
install.packages("RefManageR")
library(RefManageR)
# Define the name of the file containing the list of R packages
lib_file <- "R libraries.txt"
# Read in the list of R packages
libs <- readLines(lib_file)
# Generate bibtex citations for each R package
cits <- RIS(PackageInfo(libs))
# Define the name of the file containing the list of R packages
lib_file <- "R_libraries.txt"
# Read in the list of R packages
libs <- readLines(lib_file)
# Define the name of the file containing the list of R packages
lib_file <- "R libraries.txt"
# Read in the list of R packages
libs <- readLines(lib_file)
# Generate bibtex entries for each R package
entries <- lapply(libs, bibentry)
# Convert the entries to a character vector of bibtex citations
cits <- paste0(unlist(entries), collapse = "\n\n")
# Write the citations to a bibtex file
write_bib(cits, file = "references.bib")
install.packages("RefManageRPlugin")
library(tools)
library(RefManageR)
library(RefManageRPlugin)
install.packages("RefManageRPlugin")
# Load the required libraries
library(tools)
library(RefManageR)
library(RefManageRPlugin)
# Define the name of the file containing the list of R packages
lib_file <- "R libraries.txt"
# Read in the list of R packages
libs <- readLines(lib_file)
# Generate bibtex entries for each R package
entries <- lapply(libs, bibentry)
# Convert the entries to a character vector of bibtex citations
cits <- paste0(unlist(entries), collapse = "\n\n")
cits
libs
bibentry
libs
# Generate bibtex entries for each R package
entries <- lapply(libs, bibentry)
entries
{ # Polynomial Model Timed
poly.start <- Sys.time()
svm_poly <- svm(legitimate ~ ., data = train, kernel = "polynomial", degree = 4, coef0 = 1)
#svm_poly <- train(legitimate ~ ., data = train, method = "svmPoly", trControl = ctrl, degree = 2, coef0 = 1)
poly.end <- Sys.time()
poly.time <- poly.end - poly.start
poly.time
}
svm_poly
svm_poly$labels
{ # Polynomial Model Timed
poly.start <- Sys.time()
# Load the required library
library(e1071)
set.seed(568)
cv <- trainControl(method = "cv", number = 10)
# Train the model using 10-fold cross-validation
svm_poly_cv <- train(legitimate ~ ., data = train, method = "svmPoly",
trControl = cv, kernel = "polynomial", degree = 4, coef0 = 1)
#svm_poly <- train(legitimate ~ ., data = train, method = "svmPoly", trControl = ctrl, degree = 2, coef0 = 1)
poly.end <- Sys.time()
poly.time <- poly.end - poly.start
poly.time
}
cv
# Train the model using 10-fold cross-validation
svm_poly_cv <- train(legitimate ~ ., data = train, method = "svmPoly",
trControl = cv, kernel = "polynomial", degree = 4, coef0 = 1)
train
test
# Train the model using 10-fold cross-validation
svm_poly_cv <- train(legitimate ~ ., data = train, method = "svmPoly",
trControl = cv, kernel = "polynomial", degree = 4, coef0 = 1)
# Check for missing values in the train dataset
sum(!complete.cases(train))
# Train the model using 10-fold cross-validation
svm_poly_cv <- train(legitimate ~ ., data = train, method = "svmPoly",
trControl = cv, kernel = "polynomial", degree = 2, coef0 = 1)
{ # Polynomial Model Timed
poly.start <- Sys.time()
svm_poly <- svm(legitimate ~ ., data = train, kernel = "polynomial", degree = 4, coef0 = 1)
poly.end <- Sys.time()
poly.time <- poly.end - poly.start
poly.time
}
svm_poly
{
# Make predictions on the test dataset
svm_poly_pred <- predict(svm_poly, newdata = test)
# Calculate the accuracy and kappa
svm_poly_acc <- confusionMatrix(data = svm_poly_pred, reference = test$legitimate)$overall[1]
svm_poly_kappa <- confusionMatrix(data = svm_poly_pred, reference = test$legitimate)$overall[2]
# Calculate the AUC
svm_poly_auc <- roc(test$legitimate, predict(svm_poly, newdata = test, decision.values = TRUE))$auc
# Print the results
cat("Accuracy:", svm_poly_acc, "\n")
cat("Kappa:", svm_poly_kappa, "\n")
cat("AUC:", svm_poly_auc, "\n")
}
svm_poly_pred
svm_poly_acc
svm_poly_kappa
svm_poly_auc
# Calculate the AUC
svm_poly_auc <- roc(test$legitimate, predict(svm_poly, newdata = test, decision.values = FALSE))$auc
{
# Load the required libraries
library(e1071)
library(caret)
library(pROC)
# Make predictions on the test dataset
svm_poly_pred <- predict(svm_poly, newdata = test)
# Convert factor predictions to numeric
svm_poly_pred_num <- as.numeric(svm_poly_pred) - 1
# Calculate the accuracy and kappa
svm_poly_acc <- confusionMatrix(data = svm_poly_pred, reference = test$legitimate)$overall[1]
svm_poly_kappa <- confusionMatrix(data = svm_poly_pred, reference = test$legitimate)$overall[2]
# Calculate the AUC
svm_poly_auc <- roc(test$legitimate, svm_poly_pred_num)$auc
}
cat("AUC:", svm_poly_auc, "\n")
poly.time
{
# Load the required libraries
library(e1071)
library(caret)
library(ROCR)
# Make predictions on the test dataset
svm_poly_pred <- predict(svm_poly, newdata = test)
# Convert factor predictions to numeric
svm_poly_pred_num <- as.numeric(svm_poly_pred) - 1
# Create a prediction object
svm_poly_pred_obj <- prediction(svm_poly_pred_num, test$legitimate)
# Calculate the false positive rate and positive predictive value
svm_poly_fpr <- performance(svm_poly_pred_obj, "fp")@y.values[[1]]
svm_poly_ppv <- performance(svm_poly_pred_obj, "ppv")@y.values[[1]]
# Print the results
cat("False Positive Rate:", svm_poly_fpr, "\n")
cat("Positive Predictive Value:", svm_poly_ppv, "\n")
}
{
# Load the required libraries
library(e1071)
library(caret)
library(ROCR)
# Make predictions on the test dataset
svm_poly_pred <- predict(svm_poly, newdata = test)
# Convert factor predictions to numeric
svm_poly_pred_num <- as.numeric(svm_poly_pred) - 1
# Create a prediction object
svm_poly_pred_obj <- prediction(svm_poly_pred_num, test$legitimate)
# Calculate the false positive rate and positive predictive value
svm_poly_perf <- performance(svm_poly_pred_obj, "tpr", "ppv")
svm_poly_fpr <- svm_poly_perf@y.values[[1]][[1]]
svm_poly_ppv <- svm_poly_perf@y.values[[2]][[1]]
# Print the results
cat("False Positive Rate:", svm_poly_fpr, "\n")
cat("Positive Predictive Value:", svm_poly_ppv, "\n")
}
svm_poly_ppv
svm_poly_fpr
{
library(caret)
# Create predictions on the test set
svm_poly_pred <- predict(svm_poly, newdata = test)
# Create the confusion matrix
confusionMatrix(data = svm_poly_pred, reference = test$legitimate)
}
3274 / (3274+ 64677)
# Print the results
cat("Accuracy:", svm_poly_acc, "\n")
cat("Kappa:", svm_poly_kappa, "\n")
cat("AUC:", svm_poly_auc, "\n")
library(caret)
{
library(caret)
# Create predictions on the test set
svm_poly_pred <- predict(svm_poly, newdata = test)
# Create the confusion matrix
confusionMatrix(data = svm_poly_pred, reference = test$legitimate)
# Calculate the accuracy and kappa
svm_poly_acc <- confusionMatrix(data = svm_poly_pred, reference = test$legitimate)$overall[1]
svm_poly_kappa <- confusionMatrix(data = svm_poly_pred, reference = test$legitimate)$overall[2]
# Calculate the AUC
svm_poly_pred_num <- as.numeric(svm_poly_pred) - 1
svm_poly_auc <- roc(test$legitimate, predict(svm_poly, newdata = test, decision.values = FALSE))$auc
# Print the results
cat("Accuracy:", svm_poly_acc, "\n")
cat("Kappa:", svm_poly_kappa, "\n")
cat("AUC:", svm_poly_auc, "\n")
}
{ # Linear Model Metrics
library(pROC)
library(caret)
# Create predictions on the test set
svm_linear_pred <- predict(svm_linear, newdata = test)
# Create the confusion matrix
confusionMatrix(data = svm_linear_pred, reference = test$legitimate)
# Extract the accuracy and kappa
accuracy <- confusionMatrix(data = svm_linear_pred, reference = test$legitimate)$overall['Accuracy']
kappa <- confusionMatrix(data = svm_linear_pred, reference = test$legitimate)$overall['Kappa']
# Extract the AUC
svm_linear_auc <- roc(test$legitimate, predict(svm_linear, newdata = test, type = 'prob'))$auc
}
svm_linear
{# Linear Model Timed
linear.start <- Sys.time()
svm_linear <- train(legitimate ~ ., data = train, method = "svmLinear", trControl = ctrl)
linear.end <- Sys.time()
linear.time <- linear.end - linear.start
linear.time
}
{# Linear Model Timed
linear.start <- Sys.time()
svm_linear <- svm(legitimate ~ ., data = train, kernel = "linear", cost = 1)
linear.end <- Sys.time()
linear.time <- linear.end - linear.start
linear.time
}
{ # Linear Model Metrics
library(pROC)
library(caret)
# Create predictions on the test set
svm_linear_pred <- predict(svm_linear, newdata = test)
# Create the confusion matrix
confusionMatrix(data = svm_linear_pred, reference = test$legitimate)
# Extract the accuracy and kappa
accuracy <- confusionMatrix(data = svm_linear_pred, reference = test$legitimate)$overall['Accuracy']
kappa <- confusionMatrix(data = svm_linear_pred, reference = test$legitimate)$overall['Kappa']
# Extract the AUC
svm_linear_auc <- roc(test$legitimate, predict(svm_linear, newdata = test, type = 'prob'))$auc
}
# Extract the AUC
svm_linear_auc <- roc(test$legitimate, predict(svm_linear, newdata = test, decision.values = TRUE))$auc
cat("Acc:", accuracy, " Kappa:", kappa, " AUC:", svm_linear_auc)
accuracy
kappa
svm_linear_auc <- roc(test$legitimate, predict(svm_linear, newdata = test, decision.values = TRUE))$auc
svm_linear_auc
# Extract the AUC
svm_linear_auc <- roc(test$legitimate, predict(svm_linear, newdata = test, decision.values = FALSE))$auc
# Extract the AUC
svm_linear_pred_num <- as.numeric(svm_linear_pred) - 1
svm_linear_pred_num
svm_linear_auc <- roc(test$legitimate, svm_linear_pred_num)$auc
svm_linear_auc
cat("Acc:", accuracy, " Kappa:", kappa, " AUC:", svm_linear_auc)
# Create the confusion matrix
confusionMatrix(data = svm_linear_pred, reference = test$legitimate)
8085 / (8085+59866)
{# RBF Model Timed
rbf.start <- Sys.time()
svm_rbf <- svm(legitimate ~ ., data = train, kernel = "radial", gamma = 0.2)
#svm_rbf <- train(legitimate ~ ., data = train, method = "svmRadial", trControl = ctrl, gamma = 0.2)
rbf.end <- Sys.time()
rbf.time <- rbf.end - rbf.start
rbf.time
}
{# Sigmoid Model Timed
sigmoid.start <- Sys.time()
svm_sigmoid <- svm(legitimate ~ ., data = train, kernel = "sigmoid", gamma = 0.1, coef0 = 1)
#svm_sigmoid <- train(legitimate ~ ., data = train, method = "svmSigmoid", trControl = ctrl, gamma = 0.1, coef0 = 1)
sigmoid.end <- Sys.time()
sigmoid.time <- sigmoid.end - sigmoid.start
sigmoid.time}
{# RBF Model Metrics
library(pROC)
library(caret)
# Create predictions on the test set
svm_rbf_pred <- predict(svm_rbf, newdata = test)
# Create the confusion matrix
confusionMatrix(data = svm_rbf_pred, reference = test$legitimate)
# Extract the accuracy and kappa
accuracy <- confusionMatrix(data = svm_rbf_pred, reference = test$legitimate)$overall['Accuracy']
kappa <- confusionMatrix(data = svm_rbf_pred, reference = test$legitimate)$overall['Kappa']
# Extract the AUC
svm_rbf_pred_num <- as.numeric(svm_rbf_pred) - 1
svm_rbf_auc <- roc(test$legitimate, svm_rbf_pred_num)$auc
cat("Acc:", accuracy, " Kappa:", kappa, " AUC:", svm_rbf_auc)
}
# Create the confusion matrix
confusionMatrix(data = svm_rbf_pred, reference = test$legitimate)
2777/(2777+65174)
{# Sigmoid Model Metrics
svm_sigmoid_pred <- predict(svm_sigmoid, newdata = test)
confusionMatrix(data = svm_sigmoid_pred, reference = test$legitimate)
accuracy <- confusionMatrix(data = svm_sigmoid_pred, reference = test$legitimate)$overall['Accuracy']
kappa <- confusionMatrix(data = svm_sigmoid_pred, reference = test$legitimate)$overall['Kappa']
svm_sigmoid_pred_num <- as.numeric(svm_sigmoid_pred) - 1
svm_sigmoid_auc <- roc(test$legitimate, svm_sigmoid_pred_num)$auc
cat("Acc:", accuracy, " Kappa:", kappa, " AUC:", svm_sigmoid_auc)
}
confusionMatrix(data = svm_sigmoid_pred, reference = test$legitimate)
30575/(30575+ 37376 )
# Create the confusion matrix
confusionMatrix(data = svm_linear_pred, reference = test$legitimate)
# Create the confusion matrix
confusionMatrix(data = svm_poly_pred, reference = test$legitimate)
# Create the confusion matrix
confusionMatrix(data = svm_rbf_pred, reference = test$legitimate)
