#===============================================================================
# Load dependencies/modules/libraries
#===============================================================================
library(dplyr)
library(ggplot2)
library(caret)
library(corrplot)
library(lattice)
library(e1071)
#===============================================================================
# Load dataset for your machine 
#===============================================================================
# Set your working directory to the directory to where all project R Scripts
cwd <- getwd()
file.name <- "Kaggle-data-FINAL.csv"
paste(cwd, file.name ,sep="/")
df <- read.csv(paste(cwd, file.name ,sep="/"))
data.load <- df
#===============================================================================
# Pre-Process Data
# Label the response variable column name
response_var <- "legitimate" 
## Confirm there are no nulls
sum(is.na(df))
## Check for near zero variance using the nearZeroVar function
zeroVar <- nearZeroVar(df, saveMetrics=FALSE)
## Column index 10, 30, 31, 32, 33, and 47 all have zero  variance
zeroVar.names <- colnames(df[zeroVar])
trans1 <- (paste("ZeroVar column removed:", zeroVar.names, collapse = "\n"))
##Dropping near zero variance columns
df_trans1 <- df[, -zeroVar] 
##Drop the ID column because this is an index and is non-informational as well as the md5 column
id.columns <- colnames(df[1:2])
df_trans2 <- select(df_trans1, -id.columns)
trans2 <- (paste("ID column removed:", id.columns, collapse = "\n"))
## Find highly correlated variables; remove corr magnitude .8 or higher
corr_matrix <- cor(df_trans2)
high_corr <- findCorrelation(corr_matrix, cutoff = 0.8)
high.corr.names <- names(df_trans1)[high_corr]
trans3 <- (paste("High Correlation removed:", high.corr.names, collapse = "\n"))

##Remove highly correlated variables from data frame
df_trans3 <- df_trans2[, -high_corr]
##Convert outcome variable to 2-level factor
df_trans3$legitimate <- as.factor(df_trans3$legitimate)

# Removal Recap
df.preprocessed <- df_trans3
cat(trans1, trans2, trans3, sep="\n")
#===============================================================================
# Split Test Train Data
set.seed(568)
#index <- createDataPartition(y=df.preprocessed$legitimate, p = 0.7, list = FALSE)
# Intentionally reduce training set to 10%
index <- createDataPartition(y=df.preprocessed$legitimate, p = 0.1, list = FALSE)
train <- df.preprocessed[index, ]
test <- df.preprocessed[-index, ]
x_train <- train[, -which(names(train) == response_var)]
y_train <- train[, which(names(train) == response_var)]
x_test <- test[, -which(names(test) == response_var)]
y_test <- test[, which(names(test) == response_var)]
#===============================================================================
# Create Model Simple SVM on 10% training data
#===============================================================================
svm_linear <- svm(legitimate ~ ., data = train, kernel = "linear", cost = 10)
svm_predictions <- predict(svm_model, x_test, decision.values = TRUE)
confusion_matrix <- confusionMatrix(svm_predictions, y_test)

# accuracy <- sum(svm_predictions == y_test) / length(y_test)
# print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
# Create confusion matrix
# confusion_matrix <- confusionMatrix(svm_predictions, y_test)
svm.accuracy <- confusion_matrix$overall["Accuracy"]
svm.kappa <- confusion_matrix$overall["Kappa"]
# Print the confusion matrix
print(confusion_matrix$table)
# Calculate the ROC curve and AUC
library(pROC)
# Convert binary factor to numeric vector
y_test_numeric <- as.numeric(as.character(y_test))
svm_predictions_numeric <- as.numeric(as.character(svm_predictions))
roc_data <- roc(y_test_numeric, svm_predictions_numeric)
auc <- auc(roc_data)

svm.subtitle <- paste("Accuracy: ", round(svm.accuracy, 4),
                      " Kappa: ", round(svm.kappa, 4))
# Plot the ROC curve using ggplot2
library(ggplot2)
# if(!require(devtools)) install.packages("devtools")
# devtools::install_github("kassambara/ggpubr")
install.packages("ggpubr")
library(ggpubr)
library(pROC)
ggroc(roc_data, legacy.axes = TRUE, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM (AUC =", round(auc, 2), ")"),
       subtitle = svm.subtitle,
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()
#===============================================================================
# Kernel Function Comparisons

# Train and evaluate SVM models with different kernels
svm_linear <- svm(legitimate ~ ., data = train, kernel = "linear", cost = 10)
svm_poly <- svm(legitimate ~ ., data = train, kernel = "polynomial", degree = 2, coef0 = 1)
svm_rbf <- svm(legitimate ~ ., data = train, kernel = "radial", gamma = 0.1)
svm_sigmoid <- svm(legitimate ~ ., data = train, kernel = "sigmoid", gamma = 0.1, coef0 = 1)
#-------------------------------------------------------------------------------
# Predict the class labels for the test data using each SVM model
linear_pred <- predict(svm_linear, newdata = x_test, decision.values = TRUE)
poly_pred <- predict(svm_poly, newdata = x_test, decision.values = TRUE)
rbf_pred <- predict(svm_rbf, newdata = x_test, decision.values = TRUE)
sigmoid_pred <- predict(svm_sigmoid, newdata = x_test, decision.values = TRUE)
#-------------------------------------------------------------------------------
# Create Confusion Matrices for All kernels
linear_cm <- confusionMatrix(linear_pred, y_test)
poly_cm <- confusionMatrix(poly_pred, y_test)
rbf_cm <- confusionMatrix(rbf_pred, y_test)
sigmoid_cm <- confusionMatrix(sigmoid_pred, y_test)
#-------------------------------------------------------------------------------
library(ROCR)

# Calculate the predicted probabilities for each model
linear_prob <- attributes(linear_pred)$decision.values[,1]
poly_prob <- attributes(poly_pred)$decision.values[,1]
rbf_prob <- attributes(rbf_pred)$decision.values[,1]
sigmoid_prob <- attributes(sigmoid_pred)$decision.values[,1]

# Calculate the FPR and TPR for each model
linear_pred_roc <- prediction(linear_prob, y_test)
poly_pred_roc <- prediction(poly_prob, y_test)
rbf_pred_roc <- prediction(rbf_prob, y_test)
sigmoid_pred_roc <- prediction(sigmoid_prob, y_test)

linear_perf <- performance(linear_pred_roc, "tpr", "fpr")
poly_perf <- performance(poly_pred_roc, "tpr", "fpr")
rbf_perf <- performance(rbf_pred_roc, "tpr", "fpr")
sigmoid_perf <- performance(sigmoid_pred_roc, "tpr", "fpr")

# Create the ROC curve plot
{ par(mfrow=c(2,2))
  # Create the ROC curves for each kernel
  plot(linear_perf, col="red", main="ROC Curve for SVM Linear", lwd=2, xlim=c(0,1), ylim=c(0,1), xlab="False Positive Rate", ylab="True Positive Rate")
  abline(a=0, b=1, lty=2, col="black")
  plot(poly_perf, col="blue", main="ROC Curve for SVM Polynomial", lwd=2, xlim=c(0,1), ylim=c(0,1), xlab="False Positive Rate", ylab="True Positive Rate")
  abline(a=0, b=1, lty=2, col="black")
  plot(rbf_perf, col="green", main="ROC Curve for SVM RBF", lwd=2, xlim=c(0,1), ylim=c(0,1), xlab="False Positive Rate", ylab="True Positive Rate")
  abline(a=0, b=1, lty=2, col="black")
  plot(sigmoid_perf, col="purple", main="ROC Curve for SVM Sigmoid", lwd=2, xlim=c(0,1), ylim=c(0,1), xlab="False Positive Rate", ylab="True Positive Rate")
  abline(a=0, b=1, lty=2, col="black")
}
#===============================================================================
library(ggplot2)

# Combine the data into one data frame
df <- data.frame(
  fpr = c(linear_perf@fpr, poly_perf@fpr, rbf_perf@fpr, sigmoid_perf@fpr),
  tpr = c(linear_perf@tpr, poly_perf@tpr, rbf_perf@tpr, sigmoid_perf@tpr),
  kernel = rep(c("Linear", "Polynomial", "RBF", "Sigmoid"), each = length(linear_perf@fpr))
)

# Create the ggplot
ggplot(df, aes(x = fpr, y = tpr, color = kernel)) +
  geom_line(size = 2) +
  xlim(0, 1) +
  ylim(0, 1) +
  labs(title = "ROC Curves for SVM Kernels", x = "False Positive Rate", y = "True Positive Rate", color = "Kernel") +
  theme_bw() +
  theme(legend.position = "bottom")

#===============================================================================
library(pROC)
library(ggplot2)

# Convert binary factor to numeric vector
y_test_numeric <- as.numeric(as.character(y_test))
linear_pred_numeric <- as.numeric(as.character(linear_pred))
poly_pred_numeric <- as.numeric(as.character(poly_pred))
rbf_pred_numeric <- as.numeric(as.character(rbf_pred))
sigmoid_pred_numeric <- as.numeric(as.character(sigmoid_pred))

as.numeric(as.character(poly_pred))
# Calculate ROC curves and AUC for each model
linear_roc <- roc(y_test_numeric, linear_pred_numeric)
linear_auc <- auc(linear_roc)
poly_roc <- roc(y_test_numeric, poly_pred_numeric)
poly_auc <- auc(poly_roc)
rbf_roc <- roc(y_test_numeric, rbf_pred_numeric)
rbf_auc <- auc(rbf_roc)
sigmoid_roc <- roc(y_test_numeric, sigmoid_pred_numeric)
sigmoid_auc <- auc(sigmoid_roc)

# Create a dataframe with the ROC curve data for each model
roc_data <- data.frame(
  FPR = c(linear_roc$specificities, poly_roc$specificities, rbf_roc$specificities, sigmoid_roc$specificities),
  TPR = c(linear_roc$sensitivities, poly_roc$sensitivities, rbf_roc$sensitivities, sigmoid_roc$sensitivities),
  Kernel = rep(c("Linear", "Polynomial", "RBF", "Sigmoid"), each = length(linear_roc$specificities))
)

# Plot the ROC curves using ggplot2
ggplot(roc_data, aes(x = FPR, y = TPR, color = Kernel)) +
  geom_line(size = 2) +
  geom_abline(intercept = 1, slope = 1, linetype = "dashed", color = "black") +
  labs(title = "ROC Curves for SVM Kernels",
       subtitle = paste0("Linear AUC =", round(linear_auc, 2), 
                         " | Polynomial AUC =", round(poly_auc, 2),
                         " | RBF AUC =", round(rbf_auc, 2),
                         " | Sigmoid AUC =", round(sigmoid_auc, 2)),
       x = "False Positive Rate",
       y = "True Positive Rate",
       color = "Kernel") +
  theme_bw() +
  scale_x_reverse()

#===============================================================================
library(ggplot2)
install.packages("ggpubr")
library(ggpubr)
library(pROC)
# Linear kernel
ggroc(linear_roc, legacy.axes = TRUE, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM Linear Kernel (AUC =", round(linear_auc, 2), ")"),
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()

# Polynomial kernel
ggroc(poly_roc, legacy.axes = TRUE, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM Polynomial Kernel (AUC =", round(poly_auc, 2), ")"),
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()

# RBF kernel
ggroc(rbf_roc, legacy.axes = TRUE, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM RBF Kernel (AUC =", round(rbf_auc, 2), ")"),
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()

# Sigmoid kernel
ggroc(sigmoid_roc, legacy.axes = TRUE, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM Sigmoid Kernel (AUC =", round(sigmoid_auc, 2), ")"),
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()
#===============================================================================

#===============================================================================
# Validate Model
#===============================================================================

#===============================================================================
# Create Visualizations of Model Aspects
#===============================================================================

# Decision Boundary  Plots (tentative)
#===============================================================================
# Adding Micaela's code
#===============================================================================
cwd <- getwd()
file.name <- "ImportVar10.csv"
paste(cwd, file.name ,sep="/")
df <- read.csv(paste(cwd, file.name ,sep="/"))

#----------------------------------------------------------------------------------------
#Load the data set. It is new a created only using 11 var (10 predictors and 1 outcome)
# I named it ImportVar10
#ImportVar10 <- read.csv("C:/Rprojects/Malware detection project/ImportVar10.csv")
View(ImportVar10)
Malware_df <- ImportVar10 # this is the raw data as it was imported.
str(Malware_df)
#---------------------------------------------------------------------------
#Set the random number seed so we can reproduce the results
#Convert outcome variable to 2-level factor to use it for classification.
ImportVar10$legitimate <- as.factor(ImportVar10$legitimate)
response_var <- "legitimate" 
ImpVar10Classes <- as.factor(ImportVar10$legitimate) 
#Note ImpVarClasses is the outcomme variable which is a factor and I will use it later on when I am training data
str(ImportVar10)
#------------------------------------------------------------------------------
#Splitting the data 
#--------------------------------------------
set.seed(568)
##list = FALSE, a matrix of row numbers is generated.
#These samples are allocated to the training set.I have to indicate a column with the dataset so 
#the createDataPartition works.Creating the predictors df excluding the outcome variable.
predictors <- ImportVar10[,-11]
predictors
trainingindex <- createDataPartition(y=ImportVar10$legitimate, p = .70,list= FALSE) 
head(trainingindex)
traindata <-ImportVar10[trainingindex, ]
testdata <- ImportVar10[-trainingindex, ]
x_train <- traindata[, -which(names(traindata) == response_var)]
y_train <- traindata[, which(names(traindata) == response_var)]
x_test <- testdata[, -which(names(testdata) == response_var)]
y_test <- testdata[, which(names(testdata) == response_var)]
#-------------------------------------------------
#Subset the data into objects for training using.
#trainPredictors1 <- predictors[trainingindex,]
#trainClasses1 <- ImpVar10Classes[trainingindex] 
#Do the same for the test set using negative integers.
#testPredictors1 <- predictors[-trainingindex,]
#testClasses1 <- ImpVar10Classes[-trainingindex]
#str(trainPredictors1) 
#str(testPredictors1)  
#-----------------------------------------------------------------
# Resampling data 
#set.seed(568) 
#repeatedSplits <- createDataPartition(trainClasses1, p = 0.7, times = 30)
#str(repeatedSplits) 
#-------------------------------------------------------------------------------
#To create indicators for 10-fold cross-validation,
#set.seed(568)
#cvSplits <- createFolds(trainClasses1, k = 10, returnTrain = TRUE) 
#str(cvSplits)   
#Get the first set of row numbers from the list. 
#fold1 <- cvSplits[[1]] 
#To get the first 90% of the data (the first fold)
#cvPredictors1 <- trainPredictors1[fold1,] 
#cvClasses1 <- trainClasses1[fold1]
#nrow(trainPredictors1)  [1]  
#nrow(cvPredictors1)  [1]

## Training predictors
#trainPredictors <- as.matrix(trainPredictors1)
#svmPredictors <- svm(x=trainPredictors, y = trainClasses1, k= "linear",
#  preProcess = c("center", "Scale"),
#tuneLength = 10,
#  trControl = train_control)
#svmPredictors # note: Run successfully

#Predict new samples. Running test using svmPredictors
#---------- Running the test predictors - run successfully
#testPredictions <- predict(svmPredictors, newdata = testPredictors1, type = "class")
#head(testPredictions) 
#str(testPredictions)
#---------------------------------------------------------------------
#library(tidyverse)
#

#install.packages("MASS")
#library(MASS)
#install.packages("ipred")
#library(ipred)

# Building models - SVM
#set up repeated k-fold cross Validation

#-----------------------------------------------------------------------
# Create SVM model
# Create the svm model using the data set ImportVar10
set.seed(568)
svmModel <- svm(legitimate~  ., data = traindata, kernel = "linear", cost = 10 )


#svmModel1 <- svm(legitimate~  ., data = traindata) # to test the plot of svm
# plot(svmModel1, traindata) - did not run
#print(svmModel)

# Predicting ---------------------------------------------------
svmPredictors <- predict(svmModel, x_test, decision.values = TRUE)
confusion_matrix <- confusionMatrix(svmPredictors, y_test)
print(confusion_matrix)
print(confusion_matrix$table) # it shows a count of predictions per option of the outcome Var.
svm.accuracy <- confusion_matrix$overall["Accuracy"]
print(svm.accuracy)
svm.kappa <- confusion_matrix$overall["Kappa"]
print(svm.kappa)

# Calculate the ROC curve and AUC
library(pROC)
# Convert binary factor to numeric vector
y_test_numeric <- as.numeric(as.character(y_test))
svmPredictors_numeric <- as.numeric(as.character(svmPredictors))
roc_data <- roc(y_test_numeric, svmPredictors_numeric)
auc <- auc(roc_data)

svm.subtitle <- paste("Accuracy: ", round(svm.accuracy, 4),
                      " Kappa: ", round(svm.kappa, 4))
#---------------------------------------------------------------------------------
# Plot the ROC curve using ggplot2
library(ggplot2)
# if(!require(devtools)) install.packages("devtools")
# devtools::install_github("kassambara/ggpubr")
install.packages("ggpubr")
library(ggpubr)
library(pROC)
ggroc(roc_data, legacy.axes = TRUE, color = "purple") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM (AUC =", round(auc, 2), ")"),
       subtitle = svm.subtitle,
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()

#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ code below is old and I can re-use it

train_control <- trainControl(method = "cv", number=10)
set.seed(568)
#train_control

###################################
# creating model. adding kernlab
##library(kernlab)
##library(mlbench)
#Model train using the dataset ImportVar10

#svmModelTrain <- train(legitimate ~  ., data = ImportVar10, 
#      method = "svmRadial",
#      metric = "Accuracy",
#     trControl = train_control)
#svmModelTrain # note: this model run .
# Adding pre-processing to svmModelTrain
#svmModelTrainP <- train(legitimate ~  ., data = ImportVar10, 
# method = "svmRadial",
#  metric = "ROC",
# preProcess = c("center", "scale"))
#svmModelTrainP # note: this model run successfully.
# Tuning parameters
#set.seed(568)
#tuneGrid <- expand.grid(c = c(0.25, .5, 1),
#                      sigma = 0.1) # note: this run successfully.
# Creating traincontrol using 10-fold cross-validation , reaping 5 times
#set.seed(568)
#str(predictors)
#str(ImportVar10)
#svmTune <- train(legitimate ~  ., data = ImportVar10, 
#   method = "svmRadial",
#   preProcess = c("center", "scale"),
#       trControl = trainControl) 
#svmTune
# I kep getting a message saying names are not matching or something like that. 
#?make.names
######################################

