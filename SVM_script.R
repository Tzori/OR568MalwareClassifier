#===============================================================================
# Load dependencies/modules/libraries
#===============================================================================
{
library(dplyr)
library(ggplot2)
library(caret)
library(corrplot)
library(lattice)
library(e1071)
library(ggpubr)
library(pROC)
}
#===============================================================================
# Load dataset for your machine 
#===============================================================================
# Set your working directory to the directory where all project R Scripts
{
cwd <- getwd()
file.name <- "Kaggle-data-FINAL.csv"
paste(cwd, file.name ,sep="/")
df <- read.csv(paste(cwd, file.name ,sep="/"))
data.load <- df
}
#===============================================================================
# Pre-Process Data
# Label the response variable column name
response_var <- "legitimate" 
## Confirm there are no nulls
sum(is.na(df))
## Check for near zero variance using the nearZeroVar function
zeroVar <- nearZeroVar(df, saveMetrics=FALSE)
## Column index 10, 30, 31, 32, 33, and 47 all have zero  variance
zeroVar.names <- colnames(df[zeroVar])
trans1 <- (paste("ZeroVar column removed:", zeroVar.names, collapse = "\n"))
##Dropping near zero variance columns
df_trans1 <- df[, -zeroVar] 
##Drop the ID column because this is an index and is non-informational as well as the md5 column
id.columns <- colnames(df_trans1[1:2])
df_trans2 <- select(df_trans1, -id.columns)
trans2 <- (paste("ID column removed:", id.columns, collapse = "\n"))
## Find highly correlated variables; remove corr magnitude .8 or higher
corr_matrix <- cor(df_trans2)
high_corr <- findCorrelation(corr_matrix, cutoff = 0.8)
high.corr.names <- names(df_trans2)[high_corr]
trans3 <- (paste("High Correlation removed:", high.corr.names, collapse = "\n"))

##Remove highly correlated variables from data frame
df_trans3 <- df_trans2[, -high_corr]
##Convert outcome variable to 2-level factor
df_trans3$legitimate <- as.factor(df_trans3$legitimate)

# Removal Recap
df.preprocessed <- df_trans3
cat(trans1, trans2, trans3, sep="\n")
file.export <- paste(cwd,"preprocessed_data.csv",sep="/")
#===============================================================================
# Split Test Train Data
set.seed(568)
#index <- createDataPartition(y=df.preprocessed$legitimate, p = 0.7, list = FALSE)
# Intentionally reduce training set to 10% instead of 70% or 80%
index <- createDataPartition(y=df.preprocessed$legitimate, p = 0.1, list = FALSE)
train <- df.preprocessed[index, ]
test <- df.preprocessed[-index, ]
x_train <- train[, -which(names(train) == response_var)]
y_train <- train[, which(names(train) == response_var)]
x_test <- test[, -which(names(test) == response_var)]
y_test <- test[, which(names(test) == response_var)]
#===============================================================================
# Create Model Simple SVM on 10% training data
#===============================================================================
svm_linear <- svm(legitimate ~ ., data = train, kernel = "linear", cost = 10)
svm_predictions <- predict(svm_linear, x_test, decision.values = TRUE)
confusion_matrix <- confusionMatrix(svm_predictions, y_test)

# accuracy <- sum(svm_predictions == y_test) / length(y_test)
# print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
# Create confusion matrix
# confusion_matrix <- confusionMatrix(svm_predictions, y_test)
svm.accuracy <- confusion_matrix$overall["Accuracy"]
svm.kappa <- confusion_matrix$overall["Kappa"]
# Print the confusion matrix
print(confusion_matrix$table)
# Calculate the ROC curve and AUC
library(pROC)
# Convert binary factor to numeric vector
y_test_numeric <- as.numeric(as.character(y_test))
svm_predictions_numeric <- as.numeric(as.character(svm_predictions))
roc_data <- roc(y_test_numeric, svm_predictions_numeric)
auc <- auc(roc_data)

svm.subtitle <- paste("Accuracy: ", round(svm.accuracy, 4),
                      " Kappa: ", round(svm.kappa, 4))
# Plot the ROC curve using ggplot2
library(ggplot2)
# if(!require(devtools)) install.packages("devtools")
# devtools::install_github("kassambara/ggpubr")
install.packages("ggpubr")
library(ggpubr)
library(pROC)
ggroc(roc_data, legacy.axes = TRUE, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM (AUC =", round(auc, 2), ")"),
       subtitle = svm.subtitle,
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()
#===============================================================================
# Kernel Function Comparisons

# Train and evaluate SVM models with different kernels
svm_linear <- svm(legitimate ~ ., data = train, kernel = "linear", cost = 1)
svm_poly <- svm(legitimate ~ ., data = train, kernel = "polynomial", degree = 4, coef0 = 1)
svm_rbf <- svm(legitimate ~ ., data = train, kernel = "radial", gamma = 0.2)
svm_sigmoid <- svm(legitimate ~ ., data = train, kernel = "sigmoid", gamma = 0.1, coef0 = 1)
#-------------------------------------------------------------------------------
library(caret)
# Define the training control
ctrl <- trainControl(method = "cv", number = 10)
# Train and evaluate the models
set.seed(568) # for reproducibility


{# Linear Model Timed
linear.start <- Sys.time()
svm_linear <- svm(legitimate ~ ., data = train, kernel = "linear", cost = 1)
linear.end <- Sys.time()
linear.time <- linear.end - linear.start
linear.time
}
{# Linear Model Timed Optimal cost of 9
linear.start <- Sys.time()
svm_linear <- svm(legitimate ~ ., data = train, kernel = "linear", cost = 9)
linear.end <- Sys.time()
linear.time <- linear.end - linear.start
linear.time
}

{ # Linear Model Metrics
  library(pROC)
  library(caret)
  # Create predictions on the test set
  svm_linear_pred <- predict(svm_linear, newdata = test)
  # Create the confusion matrix
  confusionMatrix(data = svm_linear_pred, reference = test$legitimate)
  # Extract the accuracy and kappa
  accuracy <- confusionMatrix(data = svm_linear_pred, reference = test$legitimate)$overall['Accuracy']
  kappa <- confusionMatrix(data = svm_linear_pred, reference = test$legitimate)$overall['Kappa']
  # Extract the AUC
  svm_linear_pred_num <- as.numeric(svm_linear_pred) - 1
  svm_linear_auc <- roc(test$legitimate, svm_linear_pred_num)$auc
  cat("Acc:", accuracy, " Kappa:", kappa, " AUC:", svm_linear_auc)
}

{ # Polynomial Model Timed
poly.start <- Sys.time()
svm_poly <- svm(legitimate ~ ., data = train, kernel = "polynomial", degree = 5, coef0 = 1)
poly.end <- Sys.time()
poly.time <- poly.end - poly.start
poly.time
}
{# Polynomial Metrics
  library(caret)
  # Create predictions on the test set
  svm_poly_pred <- predict(svm_poly, newdata = test)
  # Create the confusion matrix
  confusionMatrix(data = svm_poly_pred, reference = test$legitimate)
  # Calculate the accuracy and kappa
  svm_poly_acc <- confusionMatrix(data = svm_poly_pred, reference = test$legitimate)$overall[1]
  svm_poly_kappa <- confusionMatrix(data = svm_poly_pred, reference = test$legitimate)$overall[2]
  # Calculate the AUC
  svm_poly_pred_num <- as.numeric(svm_poly_pred) - 1
  svm_poly_auc <- roc(test$legitimate, predict(svm_poly, newdata = test, decision.values = FALSE))$auc
  # Print the results
  cat("Accuracy:", svm_poly_acc, "\n")
  cat("Kappa:", svm_poly_kappa, "\n")
  cat("AUC:", svm_poly_auc, "\n")
}
{
  library(caret)
  library(ggplot2)
  # Train the SVM model with polynomial kernel
  svm_poly <- train(legitimate ~ ., data = train, method = "svmPoly",
                    trControl = trainControl(method = "cv", number = 10))
  # Compute the feature importance using permutation-based method
  importance <- varImp(svm_poly, scale = FALSE, useModel = FALSE)
  # Create a ggplot of the variable importance
  ggplot(importance, aes(x = Reorder(row.names(importance), -Overall), y = Overall)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    labs(x = "Features", y = "Importance", title = "Variable Importance Plot",
         subtitle = "Full SVM ~ Polynomial")
}

{# RBF Model Timed
rbf.start <- Sys.time()
svm_rbf <- svm(legitimate ~ ., data = train, kernel = "radial", gamma = 0.2)
rbf.end <- Sys.time()
rbf.time <- rbf.end - rbf.start
rbf.time
}



{# RBF Model Metrics
  library(pROC)
  library(caret)
  # Create predictions on the test set
  svm_rbf_pred <- predict(svm_rbf, newdata = test)
  # Create the confusion matrix
  confusionMatrix(data = svm_rbf_pred, reference = test$legitimate)
  # Extract the accuracy and kappa
  accuracy <- confusionMatrix(data = svm_rbf_pred, reference = test$legitimate)$overall['Accuracy']
  kappa <- confusionMatrix(data = svm_rbf_pred, reference = test$legitimate)$overall['Kappa']
  # Extract the AUC
  svm_rbf_pred_num <- as.numeric(svm_rbf_pred) - 1
  svm_rbf_auc <- roc(test$legitimate, svm_rbf_pred_num)$auc
  cat("Acc:", accuracy, " Kappa:", kappa, " AUC:", svm_rbf_auc)
}

{
  library(caret)
  library(ggplot2)
  
  # Train the SVM model using the train function from the caret package
  svm_rbf <- train(legitimate ~ ., data = train, method = "svmRadial",
                   trControl = trainControl(method = "cv", number = 10))
  
  # Compute variable importance using permutation-based method
  importance <- varImp(svm_rbf)
  ggplot(importance, aes(x = Reorder(row.names(importance), -Overall), y = Overall)) +
    geom_bar(stat = "identity", fill = "forestgreen") +
    labs(x = "Features", y = "Importance", title = "Variable Importance Plot",
    subtitle = "Full SVM ~ RBF")
  
}

{# Sigmoid Model Timed
sigmoid.start <- Sys.time()
svm_sigmoid <- svm(legitimate ~ ., data = train, kernel = "sigmoid", gamma = 0.1, coef0 = 1)
sigmoid.end <- Sys.time()
sigmoid.time <- sigmoid.end - sigmoid.start
sigmoid.time}
{# Sigmoid Model Metrics
  svm_sigmoid_pred <- predict(svm_sigmoid, newdata = test)
  confusionMatrix(data = svm_sigmoid_pred, reference = test$legitimate)
  accuracy <- confusionMatrix(data = svm_sigmoid_pred, reference = test$legitimate)$overall['Accuracy']
  kappa <- confusionMatrix(data = svm_sigmoid_pred, reference = test$legitimate)$overall['Kappa']
  svm_sigmoid_pred_num <- as.numeric(svm_sigmoid_pred) - 1
  svm_sigmoid_auc <- roc(test$legitimate, svm_sigmoid_pred_num)$auc
  cat("Acc:", accuracy, " Kappa:", kappa, " AUC:", svm_sigmoid_auc)
}
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
# Predict the class labels for the test data using each SVM model
linear_pred <- predict(svm_linear, newdata = x_test, decision.values = TRUE)
poly_pred <- predict(svm_poly, newdata = x_test, decision.values = TRUE)
rbf_pred <- predict(svm_rbf, newdata = x_test, decision.values = TRUE)
sigmoid_pred <- predict(svm_sigmoid, newdata = x_test, decision.values = TRUE)
#-------------------------------------------------------------------------------
# Create Confusion Matrices for All kernels
linear_cm <- confusionMatrix(linear_pred, y_test)
poly_cm <- confusionMatrix(poly_pred, y_test)
rbf_cm <- confusionMatrix(rbf_pred, y_test)
sigmoid_cm <- confusionMatrix(sigmoid_pred, y_test)
#-------------------------------------------------------------------------------
library(ROCR)

# Calculate the predicted probabilities for each model
linear_prob <- attributes(linear_pred)$decision.values[,1]
poly_prob <- attributes(poly_pred)$decision.values[,1]
rbf_prob <- attributes(rbf_pred)$decision.values[,1]
sigmoid_prob <- attributes(sigmoid_pred)$decision.values[,1]

# Calculate the FPR and TPR for each model
linear_pred_roc <- prediction(linear_prob, y_test)
poly_pred_roc <- prediction(poly_prob, y_test)
rbf_pred_roc <- prediction(rbf_prob, y_test)
sigmoid_pred_roc <- prediction(sigmoid_prob, y_test)

linear_perf <- performance(linear_pred_roc, "tpr", "fpr")
poly_perf <- performance(poly_pred_roc, "tpr", "fpr")
rbf_perf <- performance(rbf_pred_roc, "tpr", "fpr")
sigmoid_perf <- performance(sigmoid_pred_roc, "tpr", "fpr")

# Create the ROC curve plot
{ par(mfrow=c(2,2))
  # Create the ROC curves for each kernel
  plot(linear_perf, col="red", main="ROC Curve for SVM Linear", lwd=2, xlim=c(0,1), ylim=c(0,1), xlab="False Positive Rate", ylab="True Positive Rate")
  abline(a=0, b=1, lty=2, col="black")
  plot(poly_perf, col="blue", main="ROC Curve for SVM Polynomial", lwd=2, xlim=c(0,1), ylim=c(0,1), xlab="False Positive Rate", ylab="True Positive Rate")
  abline(a=0, b=1, lty=2, col="black")
  plot(rbf_perf, col="green", main="ROC Curve for SVM RBF", lwd=2, xlim=c(0,1), ylim=c(0,1), xlab="False Positive Rate", ylab="True Positive Rate")
  abline(a=0, b=1, lty=2, col="black")
  plot(sigmoid_perf, col="purple", main="ROC Curve for SVM Sigmoid", lwd=2, xlim=c(0,1), ylim=c(0,1), xlab="False Positive Rate", ylab="True Positive Rate")
  abline(a=0, b=1, lty=2, col="black")
}
#===============================================================================
library(ggplot2)

# Combine the data into one data frame
df <- data.frame(
  fpr = c(linear_perf@fpr, poly_perf@fpr, rbf_perf@fpr, sigmoid_perf@fpr),
  tpr = c(linear_perf@tpr, poly_perf@tpr, rbf_perf@tpr, sigmoid_perf@tpr),
  kernel = rep(c("Linear", "Polynomial", "RBF", "Sigmoid"), each = length(linear_perf@fpr))
)

# Create the ggplot
ggplot(df, aes(x = fpr, y = tpr, color = kernel)) +
  geom_line(size = 2) +
  xlim(0, 1) +
  ylim(0, 1) +
  labs(title = "ROC Curves for SVM Kernels", x = "False Positive Rate", y = "True Positive Rate", color = "Kernel") +
  theme_bw() +
  theme(legend.position = "bottom")

#===============================================================================
library(pROC)
library(ggplot2)

# Convert binary factor to numeric vector
y_test_numeric <- as.numeric(as.character(y_test))
linear_pred_numeric <- as.numeric(as.character(linear_pred))
poly_pred_numeric <- as.numeric(as.character(poly_pred))
rbf_pred_numeric <- as.numeric(as.character(rbf_pred))
sigmoid_pred_numeric <- as.numeric(as.character(sigmoid_pred))

as.numeric(as.character(poly_pred))
# Calculate ROC curves and AUC for each model
linear_roc <- roc(y_test_numeric, linear_pred_numeric)
linear_auc <- auc(linear_roc)
poly_roc <- roc(y_test_numeric, poly_pred_numeric)
poly_auc <- auc(poly_roc)
rbf_roc <- roc(y_test_numeric, rbf_pred_numeric)
rbf_auc <- auc(rbf_roc)
sigmoid_roc <- roc(y_test_numeric, sigmoid_pred_numeric)
sigmoid_auc <- auc(sigmoid_roc)

# Create a dataframe with the ROC curve data for each model
roc_data <- data.frame(
  FPR = c(linear_roc$specificities, poly_roc$specificities, rbf_roc$specificities, sigmoid_roc$specificities),
  TPR = c(linear_roc$sensitivities, poly_roc$sensitivities, rbf_roc$sensitivities, sigmoid_roc$sensitivities),
  Kernel = rep(c("Linear", "Polynomial", "RBF", "Sigmoid"), each = length(linear_roc$specificities))
)

# Plot the ROC curves using ggplot2
ggplot(roc_data, aes(x = FPR, y = TPR, color = Kernel)) +
  geom_line(size = 2) +
  geom_abline(intercept = 1, slope = 1, linetype = "dashed", color = "black") +
  labs(title = "ROC Curves for SVM Kernels",
       subtitle = paste0("Linear AUC =", round(linear_auc, 2), 
                         " | Polynomial AUC =", round(poly_auc, 2),
                         " | RBF AUC =", round(rbf_auc, 2),
                         " | Sigmoid AUC =", round(sigmoid_auc, 2)),
       x = "False Positive Rate",
       y = "True Positive Rate",
       color = "Kernel") +
  theme_bw() +
  scale_x_reverse()

#===============================================================================
library(ggplot2)
install.packages("ggpubr")
library(ggpubr)
library(pROC)
# Linear kernel
ggroc(linear_roc, legacy.axes = TRUE, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM Linear Kernel (AUC =", round(linear_auc, 2), ")"),
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()

# Polynomial kernel
ggroc(poly_roc, legacy.axes = TRUE, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM Polynomial Kernel (AUC =", round(poly_auc, 2), ")"),
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()

# RBF kernel
ggroc(rbf_roc, legacy.axes = TRUE, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM RBF Kernel (AUC =", round(rbf_auc, 2), ")"),
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()

# Sigmoid kernel
ggroc(sigmoid_roc, legacy.axes = TRUE, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM Sigmoid Kernel (AUC =", round(sigmoid_auc, 2), ")"),
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()
#===============================================================================
#-------------------------------------------------------------------------------
# TUNING MODELS SECTION 
#-------------------------------------------------------------------------------
#===============================================================================

#===============================================================================
# Linear SVM Model Tunings
#===============================================================================
{
#Define the number of folds for cross-validation
k <- 10
# Define vectors to store the accuracy scores and fitted models
costs <- seq(from = 1, to = 10, by = 1)
accuracy <- rep(0, length(costs))
fitted_models <- vector("list", length(costs))
# Loop over the cost values and train the linear SVM model with cross-validation
for (i in seq_along(costs)) {
  # Fit the linear SVM model with the current cost value
  svm_linear_tune <- svm(legitimate ~ ., data = train, kernel = "linear", cost = costs[i])
  # Perform k-fold cross-validation and calculate mean accuracy score
  cv_folds <- createFolds(y = train$legitimate, k = k, list = TRUE, returnTrain = FALSE)
  cv_results <- sapply(cv_folds, function(fold) {
    svm_fold <- svm(legitimate ~ ., data = train[fold,], kernel = "linear", cost = costs[i])
    mean(predict(svm_fold, train[-fold,]) == train$legitimate[-fold])
  })
  accuracy[i] <- mean(cv_results)
  # Save the fitted model to the list of models
  fitted_models[[i]] <- svm_linear_tune
}

# Plot the accuracy scores for different cost values
# Create a data frame with the cost and accuracy values
df <- data.frame(Cost = costs, Accuracy = accuracy)
# Plot the data using ggplot
library(ggplot2)
ggplot(df, aes(x = Cost, y = Accuracy)) +
  geom_line() +
  geom_point() +
  labs(title = "Linear SVM Cost v. Accuracy Comparison", x = "Cost", y = "Accuracy")


df <- data.frame(Cost = costs, Accuracy = accuracy)
# Find the maximum accuracy point
max_acc <- df$Accuracy[which.max(df$Accuracy)]

# Plot the data using ggplot and add a vertical dashed red line at the maximum accuracy point
ggplot(df, aes(x = Cost, y = Accuracy)) +
  geom_line(size= 1.5) +
  geom_point(size = 4) +
  labs(title = "Linear SVM Cost v. Accuracy Comparison", x = "Cost", y = "Accuracy") +
  geom_vline(xintercept = df$Cost[which(df$Accuracy == max_acc)], 
             linetype = "dashed", color = "red", size =1) +
  scale_x_continuous(breaks = seq(0, max(df$Cost), 2.0))

# Sort the data frame by Accuracy in descending order
df_sorted <- df[order(df$Accuracy, decreasing = TRUE),]

# Create the bar plot
ggplot(df_sorted, aes(x = Cost, y = Accuracy)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "Cost", y = "Accuracy") +
  coord_flip() +
  labs(title = "Linear SVM Cost v. Accuracy Comparison",
       x = "Cost", y = "Accuracy")

#===============================================================================
library(pROC)
library(ggplot2)

# Train linear SVM models with different cost values
costs <- seq(from = 1, to = 10, by = 1)
models <- lapply(costs, function(c) svm(legitimate ~ ., data = train, kernel = "linear", cost = c))

# Calculate AUC and ROC curve for each model
aucs <- sapply(models, function(m) roc(train$legitimate, predict(m, newdata = train)))
roc_data <- data.frame(fpr = unlist(lapply(aucs, function(a) a$specificities[[1]])),
                       tpr = unlist(lapply(aucs, function(a) a$sensitivities[[1]])),
                       cost = rep(costs, each = length(aucs[[1]]$specificities[[1]])))

# Plot ROC curves for all models
ggplot(roc_data, aes(x = fpr, y = tpr, color = as.factor(cost))) +
  geom_line() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_color_discrete(name = "Cost") +
  labs(title = "ROC Curve for Linear SVM Models",
       x = "False Positive Rate",
       y = "True Positive Rate")
}
#===============================================================================
# Polynomial SVM Model Tunings
#===============================================================================
set.seed(568)
degrees <- seq(from = 2, to = 10, by = 1)
models <- lapply(degrees, function(d) svm(legitimate ~ ., data = train, kernel = "polynomial", degree = d, coef0 = 1))
# Compute accuracies for each model
accuracies <- sapply(models, function(m) mean(predict(m, newdata = test) == test$legitimate))

# Create a data frame with the degrees and accuracies
data <- data.frame(Degree = degrees, Accuracy = accuracies)
# Find the maximum accuracy point
max_acc <- data$Accuracy[which.max(data$Accuracy)]
max_degree <- data$Degree[data$Accuracy == max_acc]
# Plot the data using ggplot and add a red dashed line at the maximum accuracy point
ggplot(data, aes(x = Degree, y = Accuracy)) +
  geom_line(size = 0.7) +
  geom_point(size = 3) +
  labs(x = "Degree", y = "Accuracy") +
  ggtitle("Accuracy of SVM models with polynomial kernel") +
  geom_vline(xintercept = max_degree, 
             linetype = "dashed", color = "red", size = 1.25) +
  geom_vline(xintercept = 5, 
             linetype = "dashed", color = "darkblue", size = 1.25)

#===============================================================================
# Radial Basis Function (RBF) SVM Model Tunings
#===============================================================================
set.seed(568)
# svm_rbf <- svm(legitimate ~ ., data = train, kernel = "radial", gamma = 0.1)
gamma.tune <- seq(from = 0.1, to = 1, by = 0.1)
models <- lapply(gamma.tune, function(g) svm(legitimate ~ ., data = train, kernel = "radial", gamma = g))
accuracies <- sapply(models, function(m) mean(predict(m, newdata = test) == test$legitimate))

{
  # Make predictions on test data
  model <- models[2]
  predictions <- predict(model, test)
  # Create confusion matrix
  predictions <- factor(predictions, levels = levels(y_test))
  y_test <- factor(y_test, levels = levels(predictions))
  library(caret)
  confusionMatrix(predictions, y_test)
  
}


data <- data.frame(Gamma = gamma.tune, Accuracy = accuracies)

# Find the corresponding Gamma value at maximum accuracy
max_acc <- data$Accuracy[which.max(data$Accuracy)]
max_gamma <- data$Gamma[data$Accuracy == max_acc]

# Create the plot
ggplot(data, aes(x = gamma.tune, y = Accuracy)) +
  geom_line() +
  geom_point() +
  labs(x = "Gamma", y = "Accuracy") +
  ggtitle("Accuracy of SVM models with Radial Basis Function kernel") +
  geom_vline(xintercept = max_gamma, 
             linetype = "dashed", color = "red", size = 1.25) +
  scale_x_continuous(breaks = gamma.tune)
#===============================================================================
# Create Visualizations of Model Aspects
#===============================================================================

# Decision Boundary  Plots (tentative)
#===============================================================================
#===============================================================================
#===============================================================================
# Adding Micaela's code
#===============================================================================
cwd <- getwd()
file.name <- "ImportVar10.csv"
paste(cwd, file.name ,sep="/")
df <- read.csv(paste(cwd, file.name ,sep="/"))

##install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(dplyr)
library(ggplot2)
library(caret)
library(corrplot)
library(e1071)
library(caTools)
library(kernlab)
library(e1071)
library(mlbench)
library(klaR)
install.packages("svmpath")
library(svmpath)
library(ROCR)
library(tidyverse)
library(caret)
#install.packages("MASS")
library(MASS)
#install.packages("ipred")
library(ipred)
library(lattice)
library(pROC)

#---------------------------------------------
#Load the data set. It is new a created only using 11 var (10 predictors and 1 outcome)
# I named it ImportVar10
#ImportVar10 <- read.csv("C:/Rprojects/Malware detection project/ImportVar10.csv")
#View(ImportVar10)

#Malware_df <- ImportVar10 # this is the raw data as it was imported.
#str(Malware_df)

#--------------------------------------------------
#Pre-processing and creating the response variable
null_cols <- which(colSums(is.na(ImportVar10)) > 0)
null_cols
sum(is.na(ImportVar10))
zeroVar <- nearZeroVar(ImportVar10, saveMetrics=FALSE)
zeroVar
skewValues <- apply(ImportVar10, 2, skewness)
head(skewValues)
corr_matrix <- cor(ImportVar10)
cor(ImportVar10)
high_corr <- findCorrelation(corr_matrix, cutoff = 0.8)
high_corr
# PCA analysis
pca<-prcomp(ImportVar10, center=TRUE, scale. = TRUE)
summary(pca)
# Calculating the variable percentage
percentVar <- pca$sd^2/sum(pca$sd^2)*100 
percentVar

plot(percentVar, xlab="Components", ylab="Percentage of Total Variance",
     type="l", main="Scree Plot of PCA Analysis", col = "turquoise")
#plot(percentVar, xlab="Components", ylab="Percentage of Total Variance", type="l", main="Plot of PCA Analysis")

trans <- preProcess(ImportVar10, method = c("BoxCox", "center", "scale", "pca"))
trans 
#Apply the transformations: 
transformed <- predict(trans, ImportVar10)
#These values are different than the previous PCA components since #they were transformed prior
head(transformed)
#--------------------------------------------
#Creating the Corrplot for the correlation Matrix
#corrplot(corr_matrix, order = "hclust")
#boxplot(ImportVar10)
highCorr <- findCorrelation(corr_matrix, cutoff = .75)
length(highCorr)
head(highCorr) 
#----------------------------------------------------------------------------------------
#Set the random number seed so we can reproduce the results
#Convert outcome variable to 2-level factor to use it for classification.
ImportVar10$legitimate <- as.factor(ImportVar10$legitimate)
ImportVar10F <- as.factor(ImportVar10$legitimate)
str(ImportVar10F)
response_var <- "legitimate" 
#Note ImpVarClasses is the outcomme variable which is a factor and I will use it later on when I am training data
str(ImportVar10)
#------------------------------------------------------------------------------
#Splitting the data 
#--------------------------------------------
set.seed(568)
trainingindex <- createDataPartition(y=ImportVar10$legitimate, p = .70,list= FALSE) 
head(trainingindex)
traindata <-ImportVar10[trainingindex, ]
testdata <- ImportVar10[-trainingindex, ]
x_train <- traindata[, -which(names(traindata) == response_var)]
y_train <- traindata[, which(names(traindata) == response_var)]
x_test <- testdata[, -which(names(testdata) == response_var)]
y_test <- testdata[, which(names(testdata) == response_var)]

#---------------------------------------------------------------------
# Building models - SVM
#set up repeated k-fold cross Validation
#-----------------------------------------------------------------------

control <- trainControl(method = "repeatcv", number=10, classProbs = TRUE)
control
svmGrid <- expand.grid(C = c(0,0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2,5), sigma = 0.1)
svmGrid
# Create the svm model using the data set ImportVar10

set.seed(568)
startTime <- Sys.time()
svmModel <- svm(legitimate~  ., data = traindata, kernel = "linear", 
                trControl= control,
                preProcess = c("center", "scale"),
                tuneGrid =svmGrid,
                tuneLength = 10,
                cost = 10 )

svmModel # model run and it took 7.453048 mins
endTime <- Sys.time()
endTime - startTime #

### ------------Variable importance for svm Radial Model-------------------------

#var_importancesvmRModel <- varImp(svmRModel, scale = FALSE)
#var_importancesvmRModel # it did not run. Error in UseMethod("varImp") : 
#no applicable method for 'varImp' applied to an object of class "c('svm.formula', 'svm')"

# Predicting svm Radial model
svmRPredictors <- predict(svmRModel, x_test, decision.values = TRUE)
confusion_matrix <- confusionMatrix(svmRPredictors, y_test)
print(confusion_matrix)
print(confusion_matrix$table) # it shows a count of predictions per option of the outcome Var.
svmRModel.accuracy <- confusion_matrix$overall["Accuracy"]
print(svmRModel.accuracy)
svmRModel.kappa <- confusion_matrix$overall["Kappa"]
print(svmRModel.kappa)
# Calculate the ROC curve and AUC
# Convert binary factor to numeric vector
y_test_numeric <- as.numeric(as.character(y_test))
svmR_predictors_numeric <- as.numeric(as.character(svmRPredictors))
roc_datasvmR <- roc(y_test_numeric, svmR_predictors_numeric)
auc <- auc(roc_datasvmR)
auc # shows the value of AUC. It is 0.973
# Plot of the ROC curve for SVM Radial Model
ggroc(roc_datasvmR, legacy.axes = TRUE, color = "purple") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM Radial (AUC =", round(auc, 2), ")"),
       #subtitle = svm.subtitle,
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()


# ------------------ Radial -----------------------------------------
# Define the number of folds for cross-validation--------------------
k <- 10
# Define vectors to store the accuracy scores and fitted models
costs <- seq(from = 1, to = 10, by = 1)
accuracy <- rep(0, length(costs))
fitted_models <- vector("list", length(costs))
# Loop over the cost values and train the linear SVM model with cross-validation
for (i in seq_along(costs))
{
  # Fit the linear SVM model(Radial) with the current cost value
  svmRModel <- svm(legitimate ~  ., data = traindata, methods = "svmRadial",
                   metric = "ROC",
                   tuneGrid = grid,
                   trControl = control) # It run successfully.
  # Perform k-fold cross-validation and calculate mean accuracy score
  cv_folds <- createFolds(y = traindata$legitimate, k = k, list = TRUE,
                          returnTrain = FALSE)
  cv_results <- sapply(cv_folds, function(fold) 
  {
    svm_fold <- svm(legitimate ~ ., data = traindata[fold,], methods = "svmRadial",
                    cost = costs[i])
    mean(predict(svm_fold, traindata[-fold,]) == traindata$legitimate[-fold]) })
  
  accuracy[i] <- mean(cv_results)
  fitted_models[[i]] <- svmRModel
} # it run successfully
print(cv_results)

#===============================================================================
# Radial Basis Function (RBF) SVM Model Tuning
#===============================================================================

########### --------------Radial----------------------------
set.seed(568)
gamma.tune <- seq(from = 0.1, to = 1, by = 0.1)
models <- lapply(gamma.tune, function(g) svmRModel <- svm(legitimate ~  ., 
                                                          data = traindata, methods = "svmRadial",
                                                          metric = "ROC", tuneGrid = grid, trControl = control, gamma = g))

accuracies <- sapply(models, function(m) mean(predict(m, newdata = testdata) == testdata$legitimate))

data <- data.frame(Gamma = gamma.tune, Accuracy = accuracies) # It runs

# Create the plot that shows the Accuracy and Gamma of data.frame using svmRModel data
ggplot(data, aes(x = gamma.tune, y = accuracies)) +
  geom_line() +
  geom_point(shape=21, size=2.,fill="purple",color="black") +
  labs(x = "Gamma", y = "Accuracy") +
  ggtitle("Accuracy of SVM models with Radial Basis Function kernel") +
  theme_minimal()


#-------------Linear---------------------------------------------
traindata$legitimate <- as.factor(traindata$legitimate)
str(traindata)
svmGrid <- expand.grid(C = c(0,0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2,5), sigma = 0.1)
svmGrid
# Convert the expand.grid to character and y_test as character. 
y_test_numeric <- as.numeric(as.character(y_test))
svmGrid_numeric <- as.numeric(as.character(svmGrid))
## SVM Linear model -----------------------------------------
startTime <- Sys.time()
svm_linear <- svm(legitimate~., data = traindata, k = "linear",
                  trControl= control,
                  preProcess = c("center", "scale"),
                  tuneGrid = svmGrid,
                  tuneLength = 10)
svm_linear # it run, need to find out how to plot it. Time difference of 3.031939 mins

endTime <- Sys.time()
endTime - startTime # it run successfully up to here.

# Predicting svm Linear model
svmLinear_Predictors <- predict(svm_linear, x_test, decision.values = TRUE)
#confusion_matrixL <- confusionMatrix(svm_linear, y_test)# Error: `data` and `reference`
#should be factors with the same levels.
#print(confusion_matrixL)
#print(confusion_matrixL$table) # it shows a count of predictions per option of the outcome Var.
svm_linear.accuracy <- confusion_matrix$overall["Accuracy"]
print(svm_linear.accuracy)
svm_linear.kappa <- confusion_matrix$overall["Kappa"]
print(svm_linear.kappa)

# Calculate the ROC curve and AUC
# Convert binary factor to numeric vector
y_test_numeric <- as.numeric(as.character(y_test))
svmLinear_Predictors_numeric <- as.numeric(as.character(svmLinear_Predictors))
roc_datasvmLinear <- roc(y_test_numeric, svmLinear_Predictors_numeric)
auc <- auc(roc_datasvmLinear)
auc
######################################
## Plot for ROC curve for sVM Linear
ggroc(roc_datasvmLinear, legacy.axes = TRUE, color = "purple") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = paste("ROC Curve for SVM Linear (AUC =", round(auc, 2), ")"),
       
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "SVM") +
  theme_bw()

# ------------------ Linear -----------------------------------------
# Define the number of folds for cross-validation
k <- 10
# Define vectors to store the accuracy scores and fitted models
costs <- seq(from = 1, to = 10, by = 1)
accuracy <- rep(0, length(costs))
fitted_models <- vector("list", length(costs))
# Loop over the cost values and train the linear SVM model with cross-validation
for (i in seq_along(costs))
{
  # Fit the linear SVM model(Radial) with the current cost value
  svm_Linear <- svm(legitimate ~  ., data = traindata, methods = "Linear",
                    metric = "ROC",
                    tuneGrid = grid,
                    trControl = control) # It run successfully.
  # Perform k-fold cross-validation and calculate mean accuracy score
  cv_foldsL <- createFolds(y = traindata$legitimate, k = k, list = TRUE,
                           returnTrain = FALSE)
  cv_resultsL <- sapply(cv_folds, function(fold) 
  {
    svm_foldL <- svm(legitimate ~ ., data = traindata[fold,], methods = "Linear",
                     cost = costs[i])
    mean(predict(svm_foldL, traindata[-fold,]) == traindata$legitimate[-fold]) })
  
  accuracy[i] <- mean(cv_results)
  fitted_models[[i]] <- svmRModel
} # it run successfully
print(cv_results)
#===============================================================================
# Linear Basis Function (RBF) SVM Model Tuning
#===============================================================================
set.seed(568)
gamma.tune1 <- seq(from = 0.1, to = 1, by = 0.1)
models1 <- lapply(gamma.tune1, function(g) svm_Linear <- svm(legitimate ~  ., 
                                                             data = traindata, methods = "Linear",
                                                             metric = "ROC", tuneGrid = grid, trControl = control, gamma = g))

accuracies1 <- sapply(models1, function(m) mean(predict(m, newdata = testdata) == testdata$legitimate))

data1 <- data.frame(Gamma = gamma.tune1, Accuracy = accuracies1) # It runs

# Create the plot that shows the Accuracy and Gamma of data.frame using linear model data
ggplot(data, aes(x = gamma.tune1, y = accuracies1)) +
  geom_line() +
  geom_point(shape=21, size=2.7,
             fill="green", color="black") +
  labs(x = "Gamma", y = "Accuracy") +
  ggtitle("Accuracy of SVM models with Linear Basis Function kernel") +
  theme_minimal()

